const db = require("../config/db");
const openai = require("../config/openai");
const deepseek = require("../config/deepseek");
const { query } = require("../config/db"); // make sure you're importing correctly
const { extractUrls, processUrls } = require("../utils/urlProcessor");
const { sanitizeDisplayName } = require("../utils/FilenameGenerator"); // âœ… ADD THIS
const llama = require("../config/llama");
const { selectOptimalModel } = require("../utils/tokenCounter");
const FileGenerator = require("../utils/fileGenerator");
// âœ… ADD THESE CONSTANTS AT THE TOP OF THE FILE
const MAX_FILE_GENERATION_TIME = 10000; // 10 seconds max per file
const MAX_CONCURRENT_FILES = 3; // Maximum files to generate simultaneously
const RESPONSE_QUALITY_THRESHOLD = 60; // Minimum quality score
const { semanticSearch } = require("../utils/semanticSearch"); // âœ… ADD THIS

// Add these imports at the top
const natural = require("natural");
const compromise = require("compromise");

// âœ… SMART FILE CREATION DETECTION - Beyond regex
function intelligentFileDetectionAnalysis(userMessage) {
  if (!userMessage || typeof userMessage !== "string") {
    return {
      shouldCreateFile: false,
      confidence: 0,
      fileType: null,
      intent: "none",
    };
  }

  const message = userMessage.toLowerCase().trim();

  // âœ… Use NLP for better understanding
  const doc = compromise(userMessage);

  // Extract verbs and nouns for intent analysis
  const verbs = doc.verbs().out("array");
  const nouns = doc.nouns().out("array");

  let confidence = 0;
  let fileType = null;
  let intent = "none";

  // âœ… HIGH CONFIDENCE INDICATORS (90-100%)
  const highConfidencePatterns = [
    /create\s+(a\s+)?(pdf|document|docx|word|excel|xlsx|txt|file)/i,
    /generate\s+(a\s+)?(pdf|document|docx|word|excel|xlsx|txt|file)/i,
    /make\s+(me\s+)?(a\s+)?(pdf|document|docx|word|excel|xlsx|txt|file)/i,
    /download\s+(a\s+)?(pdf|document|docx|word|excel|xlsx|txt|file)/i,
    /prepare\s+(a\s+)?(pdf|document|docx|word|excel|xlsx|txt|file)/i,
    /draft\s+(a\s+)?(pdf|document|docx|word|excel|xlsx|txt|file)/i,
    /write\s+(a\s+)?(pdf|document|docx|word|excel|xlsx|txt|file)/i,
  ];

  // âœ… MEDIUM CONFIDENCE INDICATORS (70-89%)
  const mediumConfidencePatterns = [
    /create.*?(letter|application|resume|cv|report|invoice|contract)/i,
    /generate.*?(letter|application|resume|cv|report|invoice|contract)/i,
    /make.*?(letter|application|resume|cv|report|invoice|contract)/i,
    /write.*?(letter|application|resume|cv|report|invoice|contract)/i,
    /draft.*?(letter|application|resume|cv|report|invoice|contract)/i,
    /prepare.*?(letter|application|resume|cv|report|invoice|contract)/i,
    /need.*?(downloadable|file|document)/i,
    /want.*?(downloadable|file|document)/i,
  ];

  // âœ… CONTEXTUAL INDICATORS (50-69%)
  const contextualPatterns = [
    /can you (create|make|generate|write|draft|prepare)/i,
    /please (create|make|generate|write|draft|prepare)/i,
    /i need (a|an|some)/i,
    /help me (create|make|generate|write|draft|prepare)/i,
    /(format|template|example) (for|of)/i,
  ];

  // âœ… Check high confidence patterns
  for (const pattern of highConfidencePatterns) {
    const match = message.match(pattern);
    if (match) {
      confidence = 95;
      fileType = detectFileType(match[0], message);
      intent = "create_file";
      break;
    }
  }

  // âœ… Check medium confidence patterns
  if (confidence === 0) {
    for (const pattern of mediumConfidencePatterns) {
      const match = message.match(pattern);
      if (match) {
        confidence = 80;
        fileType = detectDocumentType(match[0], message);
        intent = "create_document";
        break;
      }
    }
  }

  // âœ… Check contextual patterns with verb analysis
  if (confidence === 0) {
    const creationVerbs = [
      "create",
      "make",
      "generate",
      "write",
      "draft",
      "prepare",
      "build",
      "design",
    ];
    const hasCreationVerb = verbs.some((verb) =>
      creationVerbs.some((cv) => verb.toLowerCase().includes(cv))
    );

    const documentNouns = [
      "document",
      "file",
      "letter",
      "application",
      "resume",
      "report",
      "invoice",
    ];
    const hasDocumentNoun = nouns.some((noun) =>
      documentNouns.some((dn) => noun.toLowerCase().includes(dn))
    );

    if (hasCreationVerb && hasDocumentNoun) {
      confidence = 75;
      fileType = detectDocumentType(message, message);
      intent = "create_document";
    } else if (hasCreationVerb) {
      for (const pattern of contextualPatterns) {
        if (pattern.test(message)) {
          confidence = 60;
          fileType = "docx"; // Default to Word document
          intent = "possible_create";
          break;
        }
      }
    }
  }

  // âœ… NEGATIVE INDICATORS (reduce confidence)
  const negativePatterns = [
    /how to (create|make|generate)/i,
    /what is/i,
    /explain/i,
    /tell me about/i,
    /difference between/i,
    /compare/i,
    /analyze/i,
    /summarize/i,
    /just (show|display|list)/i,
  ];

  for (const pattern of negativePatterns) {
    if (pattern.test(message)) {
      confidence = Math.max(0, confidence - 30);
      if (confidence < 50) {
        intent = "information_request";
      }
      break;
    }
  }

  return {
    shouldCreateFile: confidence >= 70, // Threshold for file creation
    confidence,
    fileType: fileType || "docx",
    intent,
    analysis: {
      verbs: verbs.slice(0, 3),
      nouns: nouns.slice(0, 3),
      hasCreationIntent: confidence >= 70,
    },
  };
}

// âœ… SMART FILE TYPE DETECTION
function detectFileType(matchedText, fullMessage) {
  const text = (matchedText + " " + fullMessage).toLowerCase();

  if (/pdf/i.test(text)) return "pdf";
  if (/excel|xlsx|spreadsheet|sheet/i.test(text)) return "xlsx";
  if (/word|docx|document/i.test(text)) return "docx";
  if (/txt|text|plain/i.test(text)) return "txt";

  // Default based on content type
  if (/table|data|calculation|budget|expense/i.test(text)) return "xlsx";
  if (/letter|application|resume|report|contract/i.test(text)) return "docx";

  return "docx"; // Default
}

// âœ… SMART DOCUMENT TYPE DETECTION
function detectDocumentType(matchedText, fullMessage) {
  const text = (matchedText + " " + fullMessage).toLowerCase();

  if (/letter|application|resume|cv|report|invoice|contract/i.test(text)) {
    if (/table|budget|expense|calculation/i.test(text)) return "xlsx";
    return "docx";
  }

  return "docx";
}

// âœ… STANDARDIZED DATABASE QUERY WRAPPER
const executeQuery = async (sql, params = []) => {
  try {
    const result = await db.query(sql, params);
    // console.log("âœ… Database query successful:", result);
    // Handle different return formats consistently
    if (Array.isArray(result) && Array.isArray(result[0])) {
      return result[0]; // Return the actual rows
    }
    return result;
  } catch (error) {
    console.error("âŒ Database query error:", error);
    throw error;
  }
};

exports.createConversation = async (req, res) => {
  const user_id = req.user?.user_id;

  // âœ… STRICT USER VALIDATION
  if (!user_id || isNaN(user_id)) {
    console.error("âŒ Invalid user_id:", user_id);
    return res.status(400).json({ error: "Valid User ID is required" });
  }

  console.log("ðŸ” Creating conversation for user_id:", user_id);

  try {
    const defaultName = "New Conversation";

    // âœ… CONSISTENT DATABASE QUERY
    const recentConversations = await executeQuery(
      `SELECT id, name FROM conversations 
   WHERE user_id = ? AND is_deleted = FALSE
   ORDER BY created_at DESC 
   LIMIT 1`,
      [user_id]
    );

    console.log(
      "ðŸ” Recent conversations for user",
      user_id,
      ":",
      recentConversations
    );

    if (recentConversations && recentConversations.length > 0) {
      const recentConversation = recentConversations[0];

      // Check if this conversation has any messages
      const messageCountResult = await executeQuery(
        `SELECT COUNT(*) as count FROM chat_history WHERE conversation_id = ?`,
        [recentConversation.id]
      );

      const messageCount = messageCountResult[0]?.count || 0;

      // If no messages, reuse this conversation
      if (messageCount === 0) {
        console.log(
          "ðŸ”„ Reused empty conversation:",
          recentConversation.id,
          "for user:",
          user_id
        );
        return res.status(200).json({
          success: true,
          conversation_id: recentConversation.id,
          name: recentConversation.name,
          action: "reused",
        });
      }
    }

    // Create new conversation
    const name = req.body.name || defaultName;
    const newConversationResult = await executeQuery(
      "INSERT INTO conversations (user_id, name) VALUES (?, ?)",
      [user_id, name]
    );

    const conversation_id = newConversationResult.insertId;

    if (!conversation_id) {
      throw new Error("Failed to get insert ID");
    }

    console.log(
      "âœ… Created new conversation:",
      conversation_id,
      "for user:",
      user_id
    );

    return res.status(201).json({
      success: true,
      conversation_id,
      name,
      action: "created",
    });
  } catch (error) {
    console.error(
      "âŒ Error creating conversation for user",
      user_id,
      ":",
      error
    );
    return res.status(500).json({
      error: "Failed to create or reuse conversation",
      details: error.message,
    });
  }
};

// âœ… FIXED GET CONVERSATIONS WITH PROPER USER VALIDATION
exports.getConversations = async (req, res) => {
  const user_id = req.user?.user_id;

  // âœ… STRICT USER VALIDATION
  if (!user_id || isNaN(user_id)) {
    console.error("âŒ Invalid user_id in getConversations:", user_id);
    return res.status(401).json({ error: "Unauthorized: Invalid user ID" });
  }

  console.log("ðŸ” Fetching conversations for user_id:", user_id);

  try {
    // âœ… CONSISTENT DATABASE QUERY WITH USER VALIDATION
    const conversations = await executeQuery(
      "SELECT * FROM conversations WHERE user_id = ? AND is_deleted = FALSE ORDER BY created_at DESC",
      [user_id]
    );

    console.log(
      "âœ… Found",
      conversations.length,
      "conversations for user:",
      user_id
    );

    // âœ… LOG FIRST FEW CONVERSATION IDs FOR DEBUGGING
    if (conversations.length > 0) {
      // console.log("ðŸ” Conversation IDs:", conversations.slice(0, 3).map(c => c.id));
    }

    res.json({
      success: true,
      conversations: conversations || [],
      user_id: user_id, // Include for debugging
    });
  } catch (error) {
    console.error(
      "âŒ Error fetching conversations for user",
      user_id,
      ":",
      error.message
    );
    res.status(500).json({ error: "Failed to retrieve conversations" });
  }
};

// âœ… UPDATE YOUR getConversationHistory FUNCTION
exports.getConversationHistory = async (req, res) => {
  const { conversation_id } = req.params;
  const user_id = req.user?.user_id;

  if (!conversation_id || isNaN(conversation_id)) {
    return res.status(400).json({ error: "Valid conversation ID is required" });
  }

  if (!user_id || isNaN(user_id)) {
    console.error("âŒ Invalid user_id in getConversationHistory:", user_id);
    return res.status(401).json({ error: "Unauthorized: Invalid user ID" });
  }

  console.log(
    "ðŸ” Fetching history for conversation:",
    conversation_id,
    "user:",
    user_id
  );

  try {
    // âœ… VERIFY CONVERSATION OWNERSHIP FIRST
    const ownershipCheck = await executeQuery(
      "SELECT id FROM conversations WHERE id = ? AND user_id = ? AND is_deleted = FALSE",
      [parseInt(conversation_id), user_id]
    );

    if (!ownershipCheck || ownershipCheck.length === 0) {
      console.error(
        "âŒ Unauthorized access attempt - conversation:",
        conversation_id,
        "user:",
        user_id
      );
      return res.status(403).json({
        error: "Unauthorized: Conversation does not belong to user",
      });
    }

    // âœ… FETCH HISTORY WITH GENERATED FILES INFO
    const history = await executeQuery(
      `SELECT id, user_message AS message, response, created_at, file_names, file_path, file_metadata, suggestions, generated_file_info
       FROM chat_history
       WHERE conversation_id = ?
       ORDER BY created_at ASC`,
      [parseInt(conversation_id)]
    );

    if (!history || history.length === 0) {
      return res.status(200).json({ success: true, history: [] });
    }

    // âœ… GET ALL GENERATED FILES FOR THIS CONVERSATION (Updated query for your table structure)
    const generatedFiles = await executeQuery(
      `SELECT filename, file_data, file_metadata, mime_type, file_size, 
              COALESCE(ftp_path, '') as ftp_path, 
              COALESCE(download_url, '') as download_url, 
              created_at
       FROM generated_files 
       WHERE conversation_id = ? AND user_id = ?
       ORDER BY created_at ASC`,
      [parseInt(conversation_id), user_id]
    );

    console.log(
      `ðŸ“ Found ${generatedFiles.length} generated files for conversation ${conversation_id}`
    );

    const formattedHistory = history.map((msg) => {
      let aiGeneratedFiles = [];
      let files = [];

      console.log("ðŸ” Processing files for message:", msg.id, {
        has_file_metadata: !!msg.file_metadata,
        file_path: msg.file_path,
        file_names: msg.file_names,
      });

      if (msg.file_metadata) {
        try {
          let metadata = JSON.parse(msg.file_metadata);
          // console.log("ðŸ“„ Parsed file metadata:", metadata);

          // âœ… HANDLE ARRAY OF JSON STRINGS (Your current format)
          if (Array.isArray(metadata)) {
            files = [];
            metadata.forEach((item, index) => {
              try {
                // âœ… Parse each JSON string in the array
                const fileData =
                  typeof item === "string" ? JSON.parse(item) : item;
                // console.log(`ðŸ“ Processing file ${index + 1}:`, fileData);

                files.push({
                  file_path: fileData.file_path || msg.file_path || "",
                  file_name:
                    fileData.original_filename ||
                    fileData.display_filename ||
                    fileData.filename ||
                    msg.file_names ||
                    `file-${index + 1}`,
                  display_name: sanitizeDisplayName(
                    fileData.original_filename ||
                      fileData.display_filename ||
                      fileData.filename ||
                      msg.file_names ||
                      `file-${index + 1}`
                  ),
                  unique_filename: fileData.unique_filename || "",
                  file_size: fileData.file_size || 0,
                  mime_type: fileData.mime_type || "application/octet-stream",
                  type:
                    (fileData.original_filename || fileData.filename || "")
                      .split(".")
                      .pop() || "file",
                  upload_timestamp: fileData.upload_timestamp || msg.created_at,
                  is_secure: true,
                  extraction_status: fileData.extraction_status || "unknown",
                });
              } catch (innerParseError) {
                console.error(
                  `âŒ Error parsing file metadata item ${index}:`,
                  innerParseError
                );
                // âœ… Fallback to legacy format for this item
                files.push({
                  file_path: msg.file_path || "",
                  file_name: msg.file_names || `file-${index + 1}`,
                  display_name: sanitizeDisplayName(
                    msg.file_names || `file-${index + 1}`
                  ),
                  unique_filename: "",
                  file_size: 0,
                  mime_type: "application/octet-stream",
                  type: (msg.file_names || "").split(".").pop() || "file",
                  upload_timestamp: msg.created_at,
                  is_secure: false,
                  legacy_format: true,
                });
              }
            });
            console.log(
              "âœ… Processed files from metadata array:",
              files.length
            );
          }
          // âœ… HANDLE DIRECT OBJECT (Alternative format)
          else if (metadata && typeof metadata === "object") {
            files = [
              {
                file_path: metadata.file_path || msg.file_path || "",
                file_name:
                  metadata.original_filename ||
                  metadata.display_filename ||
                  metadata.filename ||
                  msg.file_names ||
                  "file-1",
                display_name: sanitizeDisplayName(
                  metadata.original_filename ||
                    metadata.display_filename ||
                    metadata.filename ||
                    msg.file_names ||
                    "file-1"
                ),
                unique_filename: metadata.unique_filename || "",
                file_size: metadata.file_size || 0,
                mime_type: metadata.mime_type || "application/octet-stream",
                type:
                  (metadata.original_filename || metadata.filename || "")
                    .split(".")
                    .pop() || "file",
                upload_timestamp: metadata.upload_timestamp || msg.created_at,
                is_secure: true,
                extraction_status: metadata.extraction_status || "unknown",
              },
            ];
            console.log("âœ… Processed single file from metadata object");
          }
        } catch (parseError) {
          console.error("âŒ Error parsing file metadata:", parseError);
          files = parseLegacyFileFormat(msg.file_path, msg.file_names);
        }
      } else if (msg.file_path || msg.file_names) {
        // Handle legacy format
        console.log("ðŸ“ Using legacy file format");
        files = parseLegacyFileFormat(msg.file_path, msg.file_names);
      }

      // console.log("ðŸ“Š Final files array:", files);

      // âœ… HANDLE AI GENERATED FILES
      if (msg.generated_files_info) {
        try {
          const genFilesInfo = JSON.parse(msg.generated_files_info);

          aiGeneratedFiles = genFilesInfo.map((genFileInfo) => {
            // Find matching generated file data
            const matchingGenFile = generatedFiles.find(
              (gf) =>
                gf.filename === genFileInfo.filename &&
                Math.abs(new Date(gf.created_at) - new Date(msg.created_at)) <
                  300000 // Within 5 minutes
            );

            return {
              filename: genFileInfo.filename,
              file_type: genFileInfo.file_type,
              mime_type: genFileInfo.mime_type,
              file_size: genFileInfo.file_size,
              download_url:
                genFileInfo.download_url || matchingGenFile?.download_url || "",
              ftp_path: genFileInfo.ftp_path || matchingGenFile?.ftp_path || "",
              file_data: matchingGenFile?.file_data, // Base64 data if available
              generated_at: genFileInfo.generated_at,
              is_ai_generated: true,
              download_ready: !!(
                genFileInfo.download_url || matchingGenFile?.download_url
              ),
            };
          });

          console.log(
            `ðŸ“„ AI generated files attached: ${aiGeneratedFiles.length}`
          );
        } catch (parseError) {
          console.error("âŒ Error parsing generated files info:", parseError);
        }
      }

      return {
        id: msg.id,
        sender: "user",
        message: msg.message,
        response: msg.response,
        suggestions: msg.suggestions ? JSON.parse(msg.suggestions) : [],
        files: files.length > 0 ? files : undefined,
        ai_generated_files:
          aiGeneratedFiles.length > 0 ? aiGeneratedFiles : undefined,
        created_at: msg.created_at,
      };
    });

    console.log(
      "âœ… Retrieved",
      formattedHistory.length,
      "messages for conversation:",
      conversation_id
    );
    console.log(
      "ðŸ“ Total uploaded files:",
      formattedHistory.reduce((sum, msg) => sum + (msg.files?.length || 0), 0)
    );
    console.log(
      "ðŸ¤– Total AI generated files:",
      formattedHistory.reduce(
        (sum, msg) => sum + (msg.ai_generated_files?.length || 0),
        0
      )
    );

    return res.status(200).json({
      success: true,
      history: formattedHistory,
      conversation_id: parseInt(conversation_id),
      user_id: user_id,
      stats: {
        total_messages: formattedHistory.length,
        uploaded_files: formattedHistory.reduce(
          (sum, msg) => sum + (msg.files?.length || 0),
          0
        ),
        ai_generated_files: formattedHistory.reduce(
          (sum, msg) => sum + (msg.ai_generated_files?.length || 0),
          0
        ),
      },
    });
  } catch (error) {
    console.error("âŒ Error fetching conversation history:", error.message);
    return res
      .status(500)
      .json({ error: "Failed to retrieve conversation history" });
  }
};
// âœ… HELPER FUNCTION FOR LEGACY FILE FORMAT

function parseLegacyFileFormat(filePaths, fileNames) {
  if (!filePaths && !fileNames) return [];

  const paths = filePaths ? filePaths.split(",") : [];
  const names = fileNames ? fileNames.split(",") : [];

  return paths.map((path, index) => ({
    file_path: path.trim(),
    file_name: names[index]?.trim() || `file-${index + 1}`,
    display_name: sanitizeDisplayName(
      names[index]?.trim() || `file-${index + 1}`
    ),
    type: path.split(".").pop() || "file",
    legacy_format: true,
    is_secure: false, // âœ… Legacy files may not be secure
  }));
}

// âœ… UPDATE CONVERSATION NAME WITH OWNERSHIP VALIDATION
exports.updateConversationName = async (req, res) => {
  const { conversationId } = req.params;
  const { name } = req.body;
  const user_id = req.user?.user_id;

  if (!name) {
    return res.status(400).json({ error: "New name is required" });
  }

  // âœ… USER VALIDATION
  if (!user_id || isNaN(user_id)) {
    console.error("âŒ Invalid user_id in updateConversationName:", user_id);
    return res.status(401).json({ error: "Unauthorized: Invalid user ID" });
  }

  console.log(
    "ðŸ” Updating conversation name:",
    conversationId,
    "for user:",
    user_id
  );

  try {
    // âœ… VERIFY OWNERSHIP BEFORE UPDATE
    const ownershipCheck = await executeQuery(
      "SELECT id FROM conversations WHERE id = ? AND user_id = ? AND is_deleted = FALSE",
      [conversationId, user_id]
    );

    if (!ownershipCheck || ownershipCheck.length === 0) {
      console.error(
        "âŒ Unauthorized update attempt - conversation:",
        conversationId,
        "user:",
        user_id
      );
      return res.status(403).json({
        error: "Unauthorized: Conversation does not belong to user",
      });
    }

    await executeQuery(
      "UPDATE conversations SET name = ? WHERE id = ? AND user_id = ?",
      [name, conversationId, user_id]
    );

    console.log("âœ… Updated conversation name:", conversationId, "to:", name);
    return res.status(200).json({ success: true, name });
  } catch (error) {
    console.error("âŒ Error renaming conversation:", error.message);
    return res.status(500).json({ error: "Failed to rename conversation" });
  }
};

// âœ… GET CHAT HISTORY WITH USER VALIDATION
exports.getChatHistory = async (req, res) => {
  const user_id = req.user?.user_id;

  // âœ… USER VALIDATION
  if (!user_id || isNaN(user_id)) {
    console.error("âŒ Invalid user_id in getChatHistory:", user_id);
    return res.status(401).json({ error: "Unauthorized: Invalid user ID" });
  }

  console.log("ðŸ” Fetching chat history for user_id:", user_id);

  try {
    const history = await executeQuery(
      "SELECT id, user_message AS message, response, created_at FROM chat_history WHERE user_id = ? ORDER BY created_at DESC",
      [user_id]
    );

    console.log("âœ… Found", history.length, "chat messages for user:", user_id);

    res.json({
      success: true,
      history: history.length > 0 ? history : [],
      message: history.length === 0 ? "No chat history found" : undefined,
      user_id: user_id, // Include for debugging
    });
  } catch (error) {
    console.error(
      "âŒ Error fetching chat history for user",
      user_id,
      ":",
      error.message
    );
    res.status(500).json({ error: "Failed to retrieve chat history" });
  }
};

// âœ… IMPROVED formatLikeChatGPT FUNCTION
function formatLikeChatGPT(content) {
  if (!content) return "";

  let formatted = content;

  // âœ… SKIP FORMATTING IF CONTENT HAS ESCAPED HTML OR CODE BLOCKS
  const hasCodeBlock = content.includes("```");
  const hasEscapedHtml = /&lt;|&gt;|&amp;|&quot;|&#39;/.test(content);

  if (hasCodeBlock || hasEscapedHtml) {
    // âœ… Return as-is for code blocks or escaped HTML
    return formatted;
  }

  // âœ… APPLY FORMATTING ONLY FOR REGULAR TEXT CONTENT
  formatted = formatted
    .replace(/\*\*(.*?)\*\*/g, "**$1**") // Keep bold
    .replace(/\*(.*?)\*/g, "*$1*") // Keep italic
    .replace(/`(.*?)`/g, "`$1`") // Keep inline code

    // âœ… SMART KEYWORD HIGHLIGHTING
    .replace(/\b(IMPORTANT|CRITICAL|NOTE|WARNING|ALERT)\b:/gi, "âš ï¸ **$1:**")
    .replace(/\b(TIP|PRO TIP|ADVICE|SUGGESTION)\b:/gi, "ðŸ’¡ **$1:**")
    .replace(/\b(EXAMPLE|SAMPLE|TEMPLATE)\b:/gi, "ðŸ“ **$1:**")
    .replace(/\b(SUMMARY|CONCLUSION|RESULT)\b:/gi, "ðŸ“Š **$1:**")

    // âœ… TABLE FORMATTING - ADD THIS
    .replace(/^(.+\|.+)$/gm, (match) => {
      // Convert pipe-separated lines to markdown table format
      if (match.includes("|")) {
        return match; // Keep as-is, ReactMarkdown will handle it
      }
      return match;
    })

    // âœ… LIST FORMATTING
    .replace(/^(\d+)\.\s/gm, "**$1.** ")
    .replace(/^[-â€¢*]\s/gm, "â€¢ ")

    // âœ… HEADER FORMATTING
    .replace(/^#{1}\s(.*?)$/gm, "\n## **$1**\n")
    .replace(/^#{2}\s(.*?)$/gm, "\n### **$1**\n")
    .replace(/^#{3}\s(.*?)$/gm, "\n#### **$1**\n");

  return formatted;
}

// working
exports.askChatbot = async (req, res) => {
  console.log("âœ… Received request at /chat:", req.body);

  let { userMessage, conversation_id, extracted_summary, _file_upload_ids } =
    req.body;
  const user_id = req.user?.user_id;

  // âœ… STRICT USER VALIDATION
  if (!user_id || isNaN(user_id)) {
    console.error("âŒ Invalid user_id in askChatbot:", user_id);
    return res.status(401).json({ error: "Unauthorized: Invalid user ID" });
  }

  if (!userMessage || userMessage.trim().length === 0) {
    return res.status(400).json({
      error: "User message cannot be empty",
    });
  }

  console.log(
    `ðŸ” Processing chat for user_id: ${user_id}, conversation: ${conversation_id}`
  );

  try {
    // Set headers for streaming
    res.writeHead(200, {
      "Content-Type": "text/plain; charset=utf-8",
      "Transfer-Encoding": "chunked",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Headers": "Cache-Control",
    });

    // âœ… VERIFY CONVERSATION OWNERSHIP IF PROVIDED
    if (conversation_id && !isNaN(conversation_id)) {
      try {
        const ownershipCheck = await executeQuery(
          "SELECT id FROM conversations WHERE id = ? AND user_id = ? AND is_deleted = FALSE",
          [conversation_id, user_id]
        );

        if (!ownershipCheck || ownershipCheck.length === 0) {
          console.error("âŒ Unauthorized conversation access");
          await rollbackPendingFiles(_file_upload_ids);
          res.write(
            JSON.stringify({
              type: "error",
              error: "Unauthorized: Conversation does not belong to user",
            }) + "\n"
          );
          res.end();
          return;
        }
        console.log("âœ… Conversation ownership verified");
      } catch (ownershipError) {
        console.error("âŒ Ownership check failed:", ownershipError);
        res.write(
          JSON.stringify({
            type: "error",
            error: "Database error during ownership verification",
          }) + "\n"
        );
        res.end();
        return;
      }
    }

    // ðŸš€ IMMEDIATE PARALLEL PROCESSING WITH PERFORMANCE TRACKING
    const startTime = Date.now();

    // âœ… SMART FILE ANALYSIS (with caching)
    const fileAnalysisStart = Date.now();
    const fileAnalysis = getCachedFileAnalysis(userMessage);
    logAIPerformance(fileAnalysisStart, "Smart File Analysis", {
      confidence: fileAnalysis.confidence,
      shouldCreate: fileAnalysis.shouldCreateFile,
      intent: fileAnalysis.intent,
    });

    console.log("ðŸ”„ Starting parallel processing...");

    // âœ… FIXED: Remove suggestions from parallel processing - do it after AI response
    let contextResult, fileContextResult, urlResult;

    try {
      // Task 1: URL Processing
      console.log("ðŸ”— Starting URL processing...");
      const urlProcessingPromise = processUrlsOptimized(userMessage, res).catch(
        (error) => {
          console.error("âŒ URL processing failed:", error);
          return {
            urlData: [],
            urlContent: "",
            processedUrls: [],
            fullUserMessage: userMessage,
          };
        }
      );

      // Task 2: Context Retrieval
      console.log("ðŸ“š Starting context retrieval...");
      const contextPromise = getConversationContextOptimized(
        conversation_id,
        user_id
      ).catch((error) => {
        console.error("âŒ Context retrieval failed:", error);
        return {
          summaryContext: "",
          shouldRename: false,
          newConversationName: null,
        };
      });

      // Task 3: File context
      console.log("ðŸ“„ Starting file context retrieval...");
      const fileContextPromise = getFileContextBasedOnUpload(
        conversation_id,
        user_id,
        extracted_summary,
        userMessage
      ).catch((error) => {
        console.error("âŒ File context retrieval failed:", error);
        return {
          fileContext: "",
          fileNames: [],
          fileCount: 0,
          contextType: "error",
        };
      });

      // âš¡ Get context immediately with proper error handling - ONLY 3 TASKS NOW
      console.log("â³ Waiting for parallel tasks to complete...");
      [contextResult, fileContextResult, urlResult] = await Promise.all([
        contextPromise,
        fileContextPromise,
        urlProcessingPromise,
      ]);

      console.log("âœ… Parallel processing completed successfully");
      console.log("ðŸ“Š Context result:", !!contextResult);
      console.log("ðŸ“Š File context result:", !!fileContextResult);
      console.log("ðŸ“Š URL result:", !!urlResult);
    } catch (parallelError) {
      console.error("âŒ Parallel processing failed:", parallelError);

      // Provide fallback values
      contextResult = {
        summaryContext: "",
        shouldRename: false,
        newConversationName: null,
      };
      fileContextResult = {
        fileContext: "",
        fileNames: [],
        fileCount: 0,
        contextType: "error",
      };
      urlResult = {
        urlData: [],
        urlContent: "",
        processedUrls: [],
        fullUserMessage: userMessage,
      };
    }

    const { summaryContext, shouldRename, newConversationName } = contextResult;
    const {
      fileContext = "",
      fileNames = [],
      fileCount = 0,
      contextType = "none",
    } = fileContextResult || {};

    const { urlData, urlContent, processedUrls, fullUserMessage } = urlResult;

    console.log(`âš¡ Context loaded in ${Date.now() - startTime}ms`);

    // ðŸ§  GET USER INFO FOR PERSONALIZED RESPONSES
    let userInfo = null;
    try {
      const userResult = await executeQuery(
        "SELECT username FROM users WHERE id = ?",
        [user_id]
      );
      if (userResult && userResult.length > 0) {
        userInfo = { username: userResult[0].username };
        console.log("âœ… User info loaded:", userInfo.username);
      }
    } catch (userError) {
      console.log(
        "âš ï¸ Could not fetch user info for personalization:",
        userError.message
      );
    }

    // ðŸ§  BUILD ENHANCED AI MESSAGES WITH SMART FILE DETECTION
    console.log("ðŸ§  Building AI messages...");
    const messagesBuildStart = Date.now();
    const finalMessages = buildAIMessagesWithSmartContext(
      summaryContext,
      extracted_summary,
      fullUserMessage,
      userInfo,
      fileNames,
      fileContext,
      contextType,
      urlContent,
      fileContextResult // âœ… ADD THIS PARAMETER
    );
    logAIPerformance(messagesBuildStart, "AI Messages Build", {
      messagesCount: finalMessages.length,
      fileDetected: fileAnalysis.shouldCreateFile,
    });

    console.log("ðŸ¤– Starting AI model selection and response...");

    // ðŸš€ SMART MODEL SELECTION & AI RESPONSE STREAM
    let aiResponse = "";
    let rawAiResponse = "";
    const aiStartTime = Date.now();

    const modelSelection = await selectOptimalModel(finalMessages);
    const selectedModel = modelSelection.model;

    console.log(
      `ðŸ¤– Selected Model: ${selectedModel.toUpperCase()} | Tokens: ${
        modelSelection.tokenCount
      } | File Creation: ${fileAnalysis.shouldCreateFile ? "YES" : "NO"}`
    );

    let stream;

    try {
      console.log("ðŸš€ Creating AI stream...");

      if (selectedModel === "deepseek") {
        stream = await deepseek.chat.completions.create({
          model: "deepseek-chat",
          messages: finalMessages,
          temperature: fileAnalysis.shouldCreateFile ? 0.3 : 0.7,
          max_tokens: fileAnalysis.shouldCreateFile ? 3000 : 5000,
          stream: true,
        });
      } else {
        stream = await llama.chat.completions.create({
          messages: finalMessages,
          temperature: fileAnalysis.shouldCreateFile ? 0.3 : 0.7,
          max_tokens: fileAnalysis.shouldCreateFile ? 3000 : 5000,
          stream: true,
        });
      }

      console.log("âœ… AI stream created successfully");
    } catch (modelError) {
      console.error(
        `âŒ ${selectedModel.toUpperCase()} API failed:`,
        modelError.message
      );

      if (
        _file_upload_ids &&
        Array.isArray(_file_upload_ids) &&
        _file_upload_ids.length > 0
      ) {
        try {
          await rollbackPendingFiles(_file_upload_ids);
          console.log(
            `ðŸ”„ Rolled back ${_file_upload_ids.length} pending files`
          );
        } catch (rollbackError) {
          console.error("âŒ Failed to rollback files:", rollbackError);
        }
      }

      try {
        console.log("ðŸ“¤ Sending error message to frontend...");
        res.write(
          JSON.stringify({
            type: "error",
            error:
              "I'm unable to process your request at the moment. Please try again in a few minutes.",
            timestamp: new Date().toISOString(),
          }) + "\n"
        );
        res.end();
        console.log("âœ… Error message sent to frontend");
      } catch (responseError) {
        console.error("âŒ Failed to send error response:", responseError);
      }

      return;
    }

    console.log("âœ… Model API call successful, starting stream...");
    try {
      // Send initial metadata immediately with file analysis
      res.write(
        JSON.stringify({
          type: "start",
          conversation_id,
          conversation_name: shouldRename
            ? "Generating title..."
            : newConversationName,
          conversation_renamed: shouldRename,
          file_creation_mode: fileAnalysis.shouldCreateFile,
          file_analysis: {
            confidence: fileAnalysis.confidence,
            intent: fileAnalysis.intent,
            expected_file_type: fileAnalysis.fileType,
          },
          context: {
            document_available: !!extracted_summary,
            conversation_context_available: !!summaryContext,
            uploaded_files_available: fileCount > 0,
            uploaded_files_count: fileCount,
            uploaded_file_names: fileNames,
            file_context_type: contextType,
          },
          processing_time: Date.now() - startTime,
        }) + "\n"
      );

      console.log(
        `ðŸš€ AI stream started with ${selectedModel.toUpperCase()} in ${
          Date.now() - aiStartTime
        }ms`
      );

      // âœ… ENHANCED STREAMING WITH PROPER HTML ESCAPING
      // let isInCreateFile = false;
      // let createFileBuffer = "";

      // for await (const chunk of stream) {
      //   if (chunk.choices && chunk.choices.length > 0) {
      //     const content = chunk.choices[0].delta?.content || "";
      //     if (content) {
      //       rawAiResponse += content;

      //       // âœ… DETECT CREATE_FILE START/END
      //       if (content.includes('[CREATE_FILE:')) {
      //         isInCreateFile = true;
      //         createFileBuffer = content;
      //       } else if (isInCreateFile) {
      //         createFileBuffer += content;
      //         if (content.includes(']')) {
      //           isInCreateFile = false;
      //           createFileBuffer = "";
      //         }
      //       }

      //       // âœ… SIMPLE FIX: Process content in correct order
      //       let displayContent = content;

      //       // Step 1: Convert escape sequences to actual characters
      //       displayContent = displayContent
      //         .replace(/\\n/g, '\n')       // Convert \n to actual newlines
      //         .replace(/\\t/g, '\t')       // Convert \t to actual tabs
      //         .replace(/\\\"/g, '"')       // Convert \" to quotes
      //         .replace(/\\\'/g, "'");      // Convert \' to apostrophes

      //       // Step 2: Handle HTML content ONLY inside CREATE_FILE
      //       if (isInCreateFile) {
      //         // Check if this is HTML content
      //         if (displayContent.includes('<!DOCTYPE html>') ||
      //             displayContent.includes('<html') ||
      //             displayContent.includes('<head>') ||
      //             displayContent.includes('<body>') ||
      //             displayContent.includes('<div') ||
      //             displayContent.includes('<p>') ||
      //             displayContent.includes('<h1>') ||
      //             displayContent.includes('<style>')) {

      //           // Escape HTML for display
      //           displayContent = displayContent
      //             .replace(/&/g, '&amp;')
      //             .replace(/</g, '&lt;')
      //             .replace(/>/g, '&gt;')
      //             .replace(/"/g, '&quot;')
      //             .replace(/'/g, '&#39;');
      //         }
      //       }

      //       // Step 3: Apply ChatGPT-like formatting (will skip if HTML is escaped)
      //       displayContent = formatLikeChatGPT(displayContent);

      //       aiResponse += displayContent;

      //       res.write(JSON.stringify({
      //         type: "content",
      //         content: displayContent,
      //       }) + "\n");
      //     }
      //   }
      // }
      // âœ… ENHANCED STREAMING WITH PROPER HTML ESCAPING
      // âœ… ENHANCED STREAMING WITH PROPER CODE BLOCK HANDLING FOR CREATE_FILE
      // âœ… ENHANCED STREAMING WITH PROPER CODE BLOCK HANDLING FOR CREATE_FILE
      // âœ… SIMPLE AND EFFECTIVE STREAMING WITH HTML PROTECTION
      // âœ… TARGETED FIX FOR HTML IN CREATE_FILE BLOCKS
      // âœ… SIMPLE FIX: Handle CREATE_FILE with HTML content

      // âœ… FIXED: Proper CREATE_FILE detection and handling
      let isInCreateFile = false;
      let createFileBuffer = "";
      let shouldWrapInCodeBlock = false;
      let codeBlockStarted = false;

      // for await (const chunk of stream) {
      //   if (chunk.choices && chunk.choices.length > 0) {
      //     const content = chunk.choices[0].delta?.content || "";
      //     if (content) {
      //       rawAiResponse += content;

      //       let displayContent = content;

      //       // Convert escape sequences
      //       displayContent = displayContent
      //         .replace(/\\n/g, '\n')
      //         .replace(/\\t/g, '\t')
      //         .replace(/\\\"/g, '"')
      //         .replace(/\\\'/g, "'");

      //       // Only escape HTML if we're inside CREATE_FILE content
      //       const recentContent = (aiResponse + displayContent).slice(-500);
      //       const isLikelyInCreateFile = recentContent.includes('[CREATE_FILE:') &&
      //                                   !recentContent.includes(']') &&
      //                                   recentContent.includes(':') &&
      //                                   (recentContent.match(/:/g) || []).length >= 2;

      //       if (isLikelyInCreateFile) {
      //         displayContent = displayContent
      //           .replace(/</g, '&lt;')
      //           .replace(/>/g, '&gt;');
      //       }

      //       displayContent = formatLikeChatGPT(displayContent);

      //       aiResponse += displayContent;

      //       res.write(JSON.stringify({
      //         type: "content",
      //         content: displayContent,
      //       }) + "\n");
      //     }
      //   }
      // }

      for await (const chunk of stream) {
        if (chunk.choices && chunk.choices.length > 0) {
          const content = chunk.choices[0].delta?.content || "";
          if (content) {
            rawAiResponse += content;

            let displayContent = content;

            // Convert escape sequences
            displayContent = displayContent
              .replace(/\\n/g, "\n")
              .replace(/\\t/g, "\t")
              .replace(/\\\"/g, '"')
              .replace(/\\\'/g, "'");

            // Only escape HTML if we're inside CREATE_FILE content
            const recentContent = (aiResponse + displayContent).slice(-500);
            const isLikelyInCreateFile =
              recentContent.includes("[CREATE_FILE:") &&
              !recentContent.includes("]") &&
              recentContent.includes(":") &&
              (recentContent.match(/:/g) || []).length >= 2;

            if (isLikelyInCreateFile) {
              // âœ… FIXED: Apply table formatting BEFORE HTML escaping
              displayContent = formatLikeChatGPT(displayContent);
              displayContent = displayContent
                .replace(/</g, "&lt;")
                .replace(/>/g, "&gt;");
            } else {
              // âœ… For normal content, apply formatting as usual
              displayContent = formatLikeChatGPT(displayContent);
            }

            aiResponse += displayContent;

            res.write(
              JSON.stringify({
                type: "content",
                content: displayContent,
              }) + "\n"
            );
          }
        }
      }

      logAIPerformance(aiStartTime, "AI Response Stream", {
        model: selectedModel,
        responseLength: aiResponse.length,
        fileCreationMode: fileAnalysis.shouldCreateFile,
      });

      // âœ… PROCESS FILES USING RAW RESPONSE
      let generatedFiles = [];
      let finalAiResponse = aiResponse;

      try {
        console.log(
          `ðŸ¤– Checking raw AI response for file generation requests...`
        );

        if (rawAiResponse.includes("[CREATE_FILE:")) {
          const fileGenStart = Date.now();

          res.write(
            JSON.stringify({
              type: "file_generation",
              status: "processing",
              message: "âš¡ Processing your document...",
            }) + "\n"
          );

          const fileGenerationResult = await handleAIFileGeneration(
            rawAiResponse,
            conversation_id,
            user_id,
            res
          );

          logAIPerformance(fileGenStart, "File Generation", {
            filesCreated: fileGenerationResult.generatedFiles?.length || 0,
          });

          if (fileGenerationResult.hasGeneratedFiles) {
            generatedFiles = fileGenerationResult.generatedFiles;

            // Add professional download links
            generatedFiles.forEach((file) => {
              const downloadLink = `\n\nðŸ“„ **${
                file.originalFilename || file.filename
              }.${
                file.fileType
              }** - Professional document ready!\nðŸ”— [**Download ${
                file.originalFilename || file.filename
              }**](${file.downloadUrl})\n*File size: ${(
                file.size / 1024
              ).toFixed(1)} KB*\n`;

              res.write(
                JSON.stringify({
                  type: "content",
                  content: downloadLink,
                }) + "\n"
              );
            });

            console.log(
              `âœ… AI generated ${generatedFiles.length} file(s) successfully`
            );
          }

          // Send completion event
          res.write(
            JSON.stringify({
              type: "file_created",
              status: "completed",
              files_count: generatedFiles.length,
              message:
                generatedFiles.length > 0
                  ? "ðŸŽ‰ Documents created successfully!"
                  : "âš ï¸ No files were created",
            }) + "\n"
          );
        }
      } catch (fileError) {
        console.error("âŒ AI file generation failed:", fileError);

        res.write(
          JSON.stringify({
            type: "file_error",
            error: "File creation failed",
            message: fileError.message,
          }) + "\n"
        );
      }

      // ðŸš€ HANDLE RENAME RESULT
      let finalConversationName = newConversationName;
      if (shouldRename) {
        try {
          const renameResult = await executeRename(
            conversation_id,
            userMessage,
            user_id
          );
          if (renameResult.success) {
            finalConversationName = renameResult.title;
            res.write(
              JSON.stringify({
                type: "conversation_renamed",
                conversation_id: conversation_id,
                new_name: finalConversationName,
                success: true,
              }) + "\n"
            );
          }
        } catch (renameError) {
          console.error("âŒ Rename failed:", renameError);
        }
      }

      // âœ… CONFIRM FILES AFTER SUCCESSFUL AI RESPONSE
      if (
        _file_upload_ids &&
        Array.isArray(_file_upload_ids) &&
        _file_upload_ids.length > 0
      ) {
        try {
          await confirmPendingFiles(_file_upload_ids);
          console.log(
            `âœ… Confirmed ${_file_upload_ids.length} files after successful AI response`
          );
        } catch (confirmError) {
          console.error("âŒ Failed to confirm files:", confirmError);
        }
      }

      // âœ… GENERATE SUGGESTIONS AFTER AI RESPONSE (MOVED HERE)
      console.log("ðŸ’¡ Generating suggestions based on conversation...");
      let suggestions = [];
      try {
        const suggestionStart = Date.now();
        suggestions = await generateFastSuggestions(userMessage, aiResponse);
        logAIPerformance(suggestionStart, "Suggestions Generation", {
          count: suggestions.length,
        });
        console.log("âœ… Suggestions generated:", suggestions.length);
      } catch (suggestionError) {
        console.error("âŒ Suggestions failed:", suggestionError);
        suggestions = [
          "Can you explain this further?",
          "What are some examples?",
          "How can I apply this?",
        ];
      }

      // Send final data with enhanced information
      res.write(
        JSON.stringify({
          type: "end",
          suggestions: suggestions,
          full_response: finalAiResponse,
          processed_urls: urlData.map((data) => ({
            url: data.url,
            title: data.title,
            success: !data.error,
            error: data.error,
            site_type: data.metadata?.siteType,
            content_length: data.content?.length || 0,
          })),
          // âœ… ENHANCED: Send generated files with professional info
          generated_files: generatedFiles.map((file) => ({
            filename: file.originalFilename || file.filename,
            actual_filename: file.filename,
            type: file.fileType,
            size: file.size,
            size_formatted: `${(file.size / 1024).toFixed(1)} KB`,
            download_url: file.downloadUrl,
            ai_generated: true,
            created_at: new Date().toISOString(),
            professional: true,
          })),
          // âœ… ENHANCED CONTEXT INFO
          context: {
            document_available: !!extracted_summary,
            conversation_context_available: !!summaryContext,
            url_content_available: !!urlContent,
            urls_processed: urlData.length,
            uploaded_files_available: fileCount > 0,
            uploaded_files_count: fileCount,
            file_context_type: contextType,
            files_generated: generatedFiles.length,
            ai_analysis: {
              file_creation_detected: fileAnalysis.shouldCreateFile,
              confidence: fileAnalysis.confidence,
              intent: fileAnalysis.intent,
              model_used: selectedModel,
            },
          },
          performance: {
            total_processing_time: Date.now() - startTime,
            ai_response_time: Date.now() - aiStartTime,
            files_created: generatedFiles.length,
            model_used: selectedModel.toUpperCase(),
          },
        }) + "\n"
      );

      res.end();

      // ðŸ”„ BACKGROUND PROCESSING (AFTER RESPONSE SENT)
      process.nextTick(() => {
        // âœ… ENSURE finalAiResponse includes download links
        let responseWithLinks = aiResponse;

        if (generatedFiles && generatedFiles.length > 0) {
          generatedFiles.forEach((file) => {
            const downloadLink = `\n\nðŸ“„ **${
              file.originalFilename || file.filename
            }.${
              file.fileType
            }** - Professional document ready!\nðŸ”— [**Download ${
              file.originalFilename || file.filename
            }**](${file.downloadUrl})\n*File size: ${(file.size / 1024).toFixed(
              1
            )} KB*\n`;
            responseWithLinks += downloadLink;
          });
        }

        handleAllBackgroundTasksOptimizedWithFiles(
          conversation_id,
          fullUserMessage,
          responseWithLinks,
          extracted_summary,
          suggestions,
          user_id,
          shouldRename,
          finalConversationName,
          processedUrls,
          urlData,
          urlContent,
          fileContext,
          _file_upload_ids,
          generatedFiles
        );
      });
    } catch (streamError) {
      console.error("âŒ Streaming error:", streamError);

      if (
        _file_upload_ids &&
        Array.isArray(_file_upload_ids) &&
        _file_upload_ids.length > 0
      ) {
        try {
          await rollbackPendingFiles(_file_upload_ids);
        } catch (rollbackError) {
          console.error("âŒ Failed to rollback files:", rollbackError);
        }
      }

      if (!res.headersSent) {
        try {
          res.write(
            JSON.stringify({
              type: "error",
              error:
                "I'm unable to process your request at the moment. Please try again in a few minutes.",
            }) + "\n"
          );
          res.end();
        } catch (responseError) {
          console.error(
            "âŒ Failed to send streaming error response:",
            responseError
          );
        }
      }
    }
  } catch (error) {
    console.error("âŒ Chat controller error:", error.message);
    console.error("âŒ Full error:", error);
    await rollbackPendingFiles(_file_upload_ids);

    if (!res.headersSent) {
      res.status(500).json({ error: "Internal server error" });
    }
  }
};


// âœ… REPLACE the main askChatbot function with this optimized version

// ðŸš€ IMPROVED URL PROCESSING - Process all URLs together
async function processUrlsOptimized(userMessage, res) {
  let urlData = [];
  let urlContent = "";
  let processedUrls = [];
  let fullUserMessage = userMessage || "";

  if (!userMessage) {
    return { urlData, urlContent, processedUrls, fullUserMessage };
  }

  const extractedUrls = extractUrls(userMessage);

  if (extractedUrls.length === 0) {
    return { urlData, urlContent, processedUrls, fullUserMessage };
  }

  console.log(
    `ðŸ”— Found ${extractedUrls.length} URLs - processing all together with universal extractor`
  );

  // Send URL processing status immediately
  res.write(
    JSON.stringify({
      type: "url_processing",
      status: "started",
      urls: extractedUrls,
      count: extractedUrls.length,
    }) + "\n"
  );

  try {
    // âœ… PROCESS ALL URLs TOGETHER (not individually)
    urlData = await processUrls(extractedUrls); // This processes all URLs in one call

    if (urlData && urlData.length > 0) {
      // âœ… Get all URLs that were attempted (including failed ones)
      processedUrls = extractedUrls;

      // âœ… Create URL content summary with MORE content and better formatting
      urlContent = urlData
        .filter((data) => data && data.content && !data.error)
        .map((data, index) => {
          const siteType = data.metadata?.siteType
            ? ` [${data.metadata.siteType.toUpperCase()}]`
            : "";
          const contentPreview =
            data.content.length > 4000
              ? data.content.substring(0, 4000) + "... [content truncated]"
              : data.content;

          return `=== URL ${index + 1}${siteType} ===
URL: ${data.url}
Title: ${data.title}
Description: ${data.description || "No description available"}

Content:
${contentPreview}

${"=".repeat(80)}`;
        })
        .join("\n\n");

      // âœ… Add URL references to user message
      if (processedUrls.length > 0) {
        const successfulCount = urlData.filter((d) => !d.error).length;
        fullUserMessage += `\n\n[Referenced ${successfulCount}/${processedUrls.length} URLs successfully processed]`;
      }

      // Send completion status with details
      const successfulUrls = urlData.filter((d) => d && !d.error);
      const failedUrls = urlData.filter((d) => d && d.error);

      res.write(
        JSON.stringify({
          type: "url_processing",
          status: "completed",
          total_urls: urlData.length,
          successful: successfulUrls.length,
          failed: failedUrls.length,
          content_extracted: urlContent.length > 0,
          failed_urls: failedUrls.map((d) => ({ url: d.url, error: d.error })),
          successful_urls: successfulUrls.map((d) => ({
            url: d.url,
            title: d.title,
            site_type: d.metadata?.siteType,
            content_length: d.content?.length || 0,
          })),
        }) + "\n"
      );

      console.log(
        `âœ… Batch URL processing completed: ${successfulUrls.length}/${urlData.length} successful`
      );
      console.log(
        `ðŸ“„ Total URL content: ${urlContent.length.toLocaleString()} characters`
      );
    }
  } catch (error) {
    console.error("âŒ Batch URL processing error:", error);
    res.write(
      JSON.stringify({
        type: "url_processing",
        status: "error",
        error: "Failed to process URLs in batch",
        details: error.message,
      }) + "\n"
    );
  }

  return { urlData, urlContent, processedUrls, fullUserMessage };
}

// âœ… HELPER FUNCTION: ROLLBACK PENDING FILES
async function rollbackPendingFiles(fileIds) {
  if (!fileIds || !Array.isArray(fileIds) || fileIds.length === 0) {
    return;
  }

  try {
    console.log(`ðŸ”„ Rolling back ${fileIds.length} pending files...`);

    // Delete from database
    await executeQuery(
      `DELETE FROM uploaded_files WHERE id IN (${fileIds
        .map(() => "?")
        .join(",")}) AND status = 'pending_response'`,
      fileIds
    );

    console.log(`âœ… Successfully rolled back ${fileIds.length} pending files`);
  } catch (error) {
    console.error("âŒ Failed to rollback pending files:", error);
  }
}

// âœ… HELPER FUNCTION: CONFIRM PENDING FILES
async function confirmPendingFiles(fileIds) {
  if (!fileIds || !Array.isArray(fileIds) || fileIds.length === 0) {
    return;
  }

  try {
    console.log(`âœ… Confirming ${fileIds.length} pending files...`);

    // Update status to confirmed
    await executeQuery(
      `UPDATE uploaded_files SET status = 'confirmed' WHERE id IN (${fileIds
        .map(() => "?")
        .join(",")}) AND status = 'pending_response'`,
      fileIds
    );

    console.log(`âœ… Successfully confirmed ${fileIds.length} files`);
  } catch (error) {
    console.error("âŒ Failed to confirm pending files:", error);
  }
}

// ðŸš€ OPTIMIZED CONTEXT RETRIEVAL - Single optimized query
async function getConversationContextOptimized(conversation_id, user_id) {
  if (!conversation_id) {
    return {
      summaryContext: "",
      shouldRename: false,
      newConversationName: null,
    };
  }

  try {
    // âš¡ Single optimized query to get everything we need
    const results = await executeQuery(
      `SELECT 
        c.name as conversation_name,
        ch.summarized_chat,
        ch.user_message,
        ch.response,
        ch.url_content,
        ch.extracted_text
       FROM conversations c
       LEFT JOIN chat_history ch ON ch.conversation_id = c.id
       WHERE c.id = ? AND c.user_id = ?
       ORDER BY ch.created_at DESC
       LIMIT 5`,
      [conversation_id, user_id]
    );

    let summaryContext = "";
    let shouldRename = false;
    let newConversationName = null;

    if (results && results.length > 0) {
      const conversationName = results[0]?.conversation_name;

      // Check if rename needed
      if (
        conversationName === "New Conversation" ||
        conversationName === "New Chat" ||
        !conversationName
      ) {
        shouldRename = true;
      }

      // âš¡ Priority: Use latest summarized_chat first
      const latestSummary = results.find(
        (r) => r.summarized_chat
      )?.summarized_chat;

      if (latestSummary) {
        summaryContext = latestSummary;
        console.log("âœ… Using existing summary for context");
      } else {
        // Fallback: Create quick context from recent messages
        const recentContext = results
          .filter((item) => item.user_message || item.response)
          .slice(0, 3)
          .reverse()
          .map((item) => {
            let context = "";
            if (item.user_message)
              context += `User: ${item.user_message.substring(0, 150)}\n`;
            if (item.response)
              context += `AI: ${item.response.substring(0, 150)}\n`;
            return context;
          })
          .join("");

        if (recentContext) {
          summaryContext = `Recent conversation:\n${recentContext}`;
          console.log("âœ… Using recent messages for context");
        }
      }
    }

    return { summaryContext, shouldRename, newConversationName };
  } catch (error) {
    console.error("âŒ Context fetch error:", error);
    return {
      summaryContext: "",
      shouldRename: false,
      newConversationName: null,
    };
  }
}

// async function getFileContextBasedOnUpload(
//   conversation_id,
//   user_id,
//   extracted_summary,
//   userMessage
// ) {
//   if (!conversation_id || isNaN(conversation_id)) {
//     return {
//       fileContext: "",
//       fileNames: [],
//       fileCount: 0,
//       contextType: "none",
//     };
//   }

//   try {
//     console.log(`ðŸ“„ Getting file context for conversation: ${conversation_id}`);

//     // Get ALL files from database - simple query
//     const allFiles = await executeQuery(
//       `SELECT file_path, extracted_text, file_metadata, created_at, status
//        FROM uploaded_files 
//        WHERE conversation_id = ? AND user_id = ? 
//        ORDER BY created_at DESC`,
//       [conversation_id, user_id]
//     );

//     console.log(`ðŸ” Found ${allFiles.length} total files in conversation`);

//     const fileNames = [];
//     let fullContext = "";
//     let validFileCount = 0;

//     // âœ… CHECK IF THERE'S A NEW UPLOAD
//     const hasNewUpload =
//       extracted_summary &&
//       extracted_summary.trim().length > 50 &&
//       extracted_summary !== "Success" &&
//       !extracted_summary.includes("extraction failed");

//     // âœ… PRIORITY 1: Add new upload first if exists
//     if (hasNewUpload) {
//       fullContext += `ðŸ†• NEWLY UPLOADED FILE (PRIORITY):\n${extracted_summary}\n\n${"=".repeat(
//         60
//       )}\n\n`;
//       console.log(
//         `âœ… Added NEW UPLOAD as priority: ${extracted_summary.length} chars`
//       );
//     }

//     // âœ… PRIORITY 2: Add existing files (excluding the new one if it exists)
//     if (allFiles && allFiles.length > 0) {
//       allFiles.forEach((file, index) => {
//         // Get file name
//         let fileName = "Unknown File";
//         if (file.file_metadata) {
//           try {
//             const metadata = JSON.parse(file.file_metadata);
//             fileName =
//               metadata.original_filename ||
//               metadata.display_filename ||
//               fileName;
//           } catch (e) {
//             fileName = file.file_path?.split("/").pop() || fileName;
//           }
//         }
//         fileNames.push(fileName);

//         // âœ… Include file if it has valid extracted text
//         if (
//           file.extracted_text &&
//           file.extracted_text.trim().length > 50 &&
//           !file.extracted_text.includes("extraction failed") &&
//           !file.extracted_text.includes("No readable content")
//         ) {
//           // âœ… SKIP if this is the same as new upload (avoid duplication)
//           if (hasNewUpload && file.extracted_text === extracted_summary) {
//             console.log(
//               `â­ï¸ Skipped duplicate: ${fileName} (already added as new upload)`
//             );
//             return;
//           }

//           validFileCount++;
//           const statusInfo =
//             file.status === "pending_response" ? " [RECENT]" : " [PREVIOUS]";

//           // âœ… Add as previous file context
//           fullContext += `ðŸ“Ž FILE: ${fileName}${statusInfo}\n${
//             file.extracted_text
//           }\n\n${"=".repeat(50)}\n\n`;

//           console.log(
//             `âœ… Added previous file: ${fileName} (${file.extracted_text.length} chars)`
//           );
//         } else {
//           console.log(`âŒ Skipped file: ${fileName} - invalid extracted text`);
//         }
//       });
//     }

//     // âœ… Add header for previous files if new upload exists
//     if (hasNewUpload && validFileCount > 0) {
//       fullContext = fullContext.replace(
//         "ðŸ“Ž FILE:",
//         "\nðŸ“š PREVIOUS FILES FOR REFERENCE:\n\nðŸ“Ž FILE:"
//       );
//     }

//     console.log(`ðŸ“„ PRIORITIZED FILE CONTEXT:`);
//     console.log(`   - New Upload: ${hasNewUpload ? "YES (PRIORITY)" : "No"}`);
//     console.log(`   - Previous Files: ${validFileCount}`);
//     console.log(
//       `   - Total Characters: ${fullContext.length.toLocaleString()}`
//     );

//     return {
//       fileContext: fullContext.trim(),
//       fileNames: fileNames,
//       fileCount: validFileCount + (hasNewUpload ? 1 : 0),
//       contextType: hasNewUpload ? "new_upload_priority" : "existing_files_only",
//     };
//   } catch (error) {
//     console.error("âŒ Error getting file context:", error);
//     return {
//       fileContext: "",
//       fileNames: [],
//       fileCount: 0,
//       contextType: "error",
//     };
//   }
// }

// âœ… UPDATED: Include URL content in AI context

async function getFileContextBasedOnUpload(
  conversation_id,
  user_id,
  extracted_summary,
  userMessage
) {
  if (!conversation_id || isNaN(conversation_id)) {
    return {
      fileContext: "",
      fileNames: [],
      fileCount: 0,
      contextType: "none",
    };
  }

  try {
    console.log(`ðŸ“„ Getting enhanced file context for conversation: ${conversation_id}`);
    
    // âœ… EARLY CHECK: If no files in conversation, return empty context
    const fileCount = await executeQuery(
      `SELECT COUNT(*) as count FROM uploaded_files 
       WHERE conversation_id = ? AND user_id = ?`,
      [conversation_id, user_id]
    );

    if (fileCount[0]?.count === 0) {
      console.log(`ðŸ“­ No files found in conversation ${conversation_id} - skipping RAG`);
      return {
        fileContext: "",
        fileNames: [],
        fileCount: 0,
        contextType: "no_files",
        semanticResults: {
          hasResults: false,
          chunksFound: 0,
          filesInvolved: [],
        },
      };
    }

    // âœ… GET ALL FILES FROM DATABASE FIRST
    const allFiles = await executeQuery(
      `SELECT file_path, extracted_text, file_metadata, created_at, status
       FROM uploaded_files 
       WHERE conversation_id = ? AND user_id = ? 
       ORDER BY created_at DESC`,
      [conversation_id, user_id]
    );

    console.log(`ðŸ” Found ${allFiles.length} total files in conversation ${conversation_id} for user ${user_id}`);

    // âœ… ENHANCED: Use semantic search for better context retrieval
    let semanticContext = "";
    let semanticChunks = [];
    
    // Only perform semantic search if there are files AND user message suggests file-related query
    if (allFiles.length > 0 && userMessage && userMessage.length > 10) {
      console.log(`ðŸ§  Performing semantic search for: "${userMessage.substring(0, 100)}..."`);
      console.log(`ðŸŽ¯ Search context: User ${user_id}, Conversation ${conversation_id}`);
      
      try {
       const searchResult = await semanticSearch.searchWithContext(
  userMessage,
  user_id,
  conversation_id,
  {
    limit: 10, // Get more chunks for richer context
    contextWindow: 6000, // Allow more context if needed
    includeFileStats: true,
    includeSummaries: true, // Custom option to include summaries
  }
);
// console.log('ðŸ§© Semantic Chunks for AI:', JSON.stringify(searchResult.chunks, null, 2));



        if (searchResult.hasResults) {
          semanticContext = searchResult.context;
          semanticChunks = searchResult.chunks;
          console.log(`âœ… Semantic search found ${searchResult.chunks.length} relevant chunks`);
          const filesInvolved = searchResult.chunks ? [...new Set(searchResult.chunks.map(c => c.fileName))] : [];
console.log(`ðŸ“Š Files involved: ${filesInvolved.join(', ') || 'Unknown'}`);

        }
      } catch (semanticError) {
        console.log(`âš ï¸ Semantic search failed, falling back to traditional method:`, semanticError.message);
      }
    }

    const fileNames = [];
    let fullContext = "";
    let validFileCount = 0;

    // âœ… PRIORITY 1: Add semantic search results first if available
    if (semanticContext && semanticContext.length > 100) {
      fullContext += `ðŸ§  SEMANTIC SEARCH RESULTS (Most Relevant Content):\n${semanticContext}\n\n${"=".repeat(80)}\n\n`;
      console.log(`âœ… Added semantic context: ${semanticContext.length} characters`);
    }

    // âœ… CHECK IF THERE'S A NEW UPLOAD
    const hasNewUpload =
      extracted_summary &&
      extracted_summary.trim().length > 50 &&
      extracted_summary !== "Success" &&
      !extracted_summary.includes("extraction failed");

    // âœ… PRIORITY 2: Add new upload if exists
    if (hasNewUpload) {
      fullContext += `ðŸ†• NEWLY UPLOADED FILE (PRIORITY):\n${extracted_summary}\n\n${"=".repeat(
        60
      )}\n\n`;
      console.log(
        `âœ… Added NEW UPLOAD as priority: ${extracted_summary.length} chars`
      );
    }

    // âœ… PRIORITY 3: Add existing files (excluding the new one if it exists)
    if (allFiles && allFiles.length > 0) {
      allFiles.forEach((file, index) => {
        // Get file name
        let fileName = "Unknown File";
        if (file.file_metadata) {
          try {
            const metadata = JSON.parse(file.file_metadata);
            fileName =
              metadata.original_filename ||
              metadata.display_filename ||
              fileName;
          } catch (e) {
            fileName = file.file_path?.split("/").pop() || fileName;
          }
        }
        fileNames.push(fileName);

        // âœ… Include file if it has valid extracted text
        if (
          file.extracted_text &&
          file.extracted_text.trim().length > 50 &&
          !file.extracted_text.includes("extraction failed") &&
          !file.extracted_text.includes("No readable content")
        ) {
          // âœ… SKIP if this is the same as new upload (avoid duplication)
          if (hasNewUpload && file.extracted_text === extracted_summary) {
            console.log(
              `â­ï¸ Skipped duplicate: ${fileName} (already added as new upload)`
            );
            return;
          }

          // âœ… SKIP if content is already covered by semantic search (avoid duplication)
          const isAlreadyInSemantic = semanticChunks.some(chunk => 
            chunk.fileName === fileName && 
            file.extracted_text.includes(chunk.text.substring(0, 100))
          );

          if (isAlreadyInSemantic) {
            console.log(
              `â­ï¸ Skipped ${fileName} - already covered by semantic search`
            );
            return;
          }

          validFileCount++;
          const statusInfo =
            file.status === "pending_response" ? " [RECENT]" : " [PREVIOUS]";

          // âœ… Add as previous file context (truncated if too long)
          const truncatedText = file.extracted_text.length > 2000 
            ? file.extracted_text.substring(0, 2000) + "... [truncated - use semantic search for full content]"
            : file.extracted_text;

          fullContext += `ðŸ“Ž FILE: ${fileName}${statusInfo}\n${truncatedText}\n\n${"=".repeat(50)}\n\n`;

          console.log(
            `âœ… Added previous file: ${fileName} (${file.extracted_text.length} chars, truncated: ${truncatedText.length})`
          );
        } else {
          console.log(`âŒ Skipped file: ${fileName} - invalid extracted text`);
        }
      });
    }

    // âœ… Add header for previous files if new upload exists
    if (hasNewUpload && validFileCount > 0) {
      fullContext = fullContext.replace(
        "ðŸ“Ž FILE:",
        "\nðŸ“š PREVIOUS FILES FOR REFERENCE:\n\nðŸ“Ž FILE:"
      );
    }

    // âœ… Determine context type
    let contextType = "none";
    if (semanticContext && hasNewUpload) {
      contextType = "semantic_plus_new_upload";
    } else if (semanticContext) {
      contextType = "semantic_search";
    } else if (hasNewUpload) {
      contextType = "new_upload_priority";
    } else if (validFileCount > 0) {
      contextType = "existing_files_only";
    }

    console.log(`ðŸ“„ ENHANCED FILE CONTEXT SUMMARY:`);
    console.log(`   - Semantic Search: ${semanticContext ? "YES (PRIORITY)" : "No"}`);
    console.log(`   - Semantic Chunks: ${semanticChunks.length}`);
    console.log(`   - New Upload: ${hasNewUpload ? "YES (PRIORITY)" : "No"}`);
    console.log(`   - Previous Files: ${validFileCount}`);
    console.log(`   - Context Type: ${contextType}`);
    console.log(`   - Total Characters: ${fullContext.length.toLocaleString()}`);

    return {
      fileContext: fullContext.trim(),
      fileNames: fileNames,
      fileCount: validFileCount + (hasNewUpload ? 1 : 0),
      contextType: contextType,
     semanticResults: {
  hasResults: semanticChunks.length > 0,
  chunksFound: semanticChunks.length,
  filesInvolved: semanticChunks.length > 0 ? [...new Set(semanticChunks.map(c => c.fileName))] : [],
  chunks: semanticChunks,
  chunkSummaries: semanticChunks.map(c => c.summary),
},

    };
  } catch (error) {
    console.error("âŒ Error getting enhanced file context:", error);
    return {
      fileContext: "",
      fileNames: [],
      fileCount: 0,
      contextType: "error",
      semanticResults: {
        hasResults: false,
        chunksFound: 0,
        filesInvolved: [],
      },
    };
  }
}




function buildAIMessagesWithSmartContext(
  summaryContext,
  extracted_summary,
  userMessage,
  userInfo = null,
  fileNames = [],
  fileContext = "",
  contextType = "none",
  urlContent = "",
  fileContextResult = null // âœ… ADD THIS PARAMETER
) {
  const currentDate = new Date().toLocaleDateString("en-US", {
    year: "numeric",
    month: "long",
    day: "numeric",
  });

  // âœ… INTELLIGENT FILE CREATION ANALYSIS
  const fileAnalysis = getCachedFileAnalysis(userMessage);

  console.log(`ðŸ§  AI File Analysis:`, {
    shouldCreate: fileAnalysis.shouldCreateFile,
    confidence: fileAnalysis.confidence,
    fileType: fileAnalysis.fileType,
    intent: fileAnalysis.intent,
    verbs: fileAnalysis.analysis.verbs,
    nouns: fileAnalysis.analysis.nouns,
  });

  // Build user context for personalized responses
  let userContext = "";
  if (userInfo && userInfo.username) {
    userContext = `The user's name is ${userInfo.username}. When greeting or addressing the user, you can use their name for a more personalized experience.`;
  }

  // âœ… CLEARER FILE GENERATION INSTRUCTIONS
  const enhancedFileGenerationInstructions = `
ðŸŽ¯ INTELLIGENT FILE CREATION SYSTEM:

DETECTION RULES:
- Analyze user intent beyond keywords
- Look for creation verbs: create, make, generate, write, draft, prepare, build
- Identify document nouns: file, document, letter, application, resume, report, invoice, contract
- Consider context and user's specific needs

WHEN TO CREATE FILES:
âœ… HIGH CONFIDENCE (Always create):
- "Create a PDF of..."
- "Generate a Word document for..."
- "Make me a resume"
- "Draft a letter to..."
- "Prepare an invoice"

âœ… MEDIUM CONFIDENCE (Create with explanation):
- "I need a leave application"
- "Help me write a report"
- "Can you make a contract"

âŒ DON'T CREATE (Information requests):
- "How to create a PDF"
- "What is a resume"
- "Explain document types"
- "Tell me about..."

FILE CREATION FORMAT:
[CREATE_FILE:type:filename:content]

SUPPORTED TYPES: pdf, docx, xlsx, txt

CONTENT FORMATTING RULES:
- Write content with natural line breaks - DO NOT use \\n
- For HTML/CSS content, ALWAYS wrap in code blocks: \`\`\`html ... \`\`\`
- Use **text** for bold headings
- Include complete, professional content with proper structure
- No file extensions in filename
- Ensure content is substantial (minimum 100 characters)
- Format content naturally like you would in a normal response

SPECIAL HANDLING FOR CODE/HTML:
- When creating HTML files, save as .txt but include complete HTML structure
- Preserve proper indentation and formatting for code
- Don't escape HTML tags in file content - keep them as valid HTML

EXAMPLE FOR HTML:
User: "Create an HTML file for Hello World"
Response: "I'll create an HTML file with CSS styling for a Hello World page.

[CREATE_FILE:txt:hello_world_html:\`\`\`html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hello World</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin-top: 50px;
        }
    </style>
</head>
<body>
    <h1>Hello World!</h1>
    <p>Welcome to my webpage</p>
</body>
</html>
\`\`\`]

Your HTML file has been created with proper structure and styling."
RESPONSE STYLE:
1. First acknowledge: "I'll create [document type] for you."
2. Then create the file with [CREATE_FILE:...]
3. Provide brief context about the document

EXAMPLE:
User: "Create a leave application for John Doe"
Response: "I'll create a professional leave application for John Doe.

[CREATE_FILE:docx:Leave_Application_John_Doe:**LEAVE APPLICATION**

**To:** [Principal/Manager Name]
**From:** John Doe
**Date:** [Current Date]
**Subject:** Application for Leave

Respected Sir/Madam,

I am writing to formally request leave from [Start Date] to [End Date] due to [Reason for leave].

I have ensured that all my current projects and responsibilities will be properly managed during my absence. I will coordinate with my team members to ensure smooth workflow continuation.

I would be grateful if you could approve my leave request. I will be available via email for any urgent matters that may require my attention.

Thank you for your understanding and consideration.

**Sincerely,**
**John Doe**
**[Position]**
**[Contact Information]**
**[Employee ID]**]

Your professional leave application document has been created and is ready for download."

CRITICAL: Write content naturally with proper line breaks. Never use \\n sequences.
CRITICAL: Write content naturally with proper formatting. For HTML content, preserve all tags and structure.
`;
  let systemPrompt;

  if (fileAnalysis.shouldCreateFile) {
    systemPrompt = {
      role: "system",
      content: `You are QhashAI â€” an intelligent AI assistant by QuantumHash team (2024).

Current date: ${currentDate}.
${userContext}

ðŸŽ¯ FILE CREATION MODE ACTIVATED (Confidence: ${fileAnalysis.confidence}%)

ANALYSIS RESULTS:
- Intent: ${fileAnalysis.intent}
- Recommended file type: ${fileAnalysis.fileType}
- User wants: ${fileAnalysis.analysis.verbs.join(
        ", "
      )} ${fileAnalysis.analysis.nouns.join(", ")}

${enhancedFileGenerationInstructions}

RESPONSE STRATEGY:
1. Acknowledge the file creation request professionally
2. Create the file using [CREATE_FILE:type:filename:content] format
3. Ensure content is complete, professional, and properly formatted
4. Use business-appropriate language and structure
5. Include all necessary sections and details

Remember: The user specifically wants a file created. Don't just provide information - CREATE THE ACTUAL FILE.`,
    };
  } else {
    systemPrompt = {
      role: "system",
      content: `You are QhashAI â€” an intelligent AI assistant by QuantumHash team (2024).

Current date: ${currentDate}.
${userContext}

ðŸ’¬ CONVERSATION MODE (File creation not detected)

You can analyze content from URLs and documents. When referencing external content, cite sources clearly.
If you are provided with file chunks or summaries, always use them as the primary source for your answer.


Be helpful, accurate, professional, and engaging. Use appropriate emojis and formatting for better readability.

If the user later asks for file creation, you can create documents using the [CREATE_FILE:type:filename:content] format.`,
    };
  }

  const finalMessages = [systemPrompt];

  // Add conversation context if available
  if (summaryContext) {
    finalMessages.push({
      role: "system",
      content: `CONVERSATION CONTEXT: ${summaryContext}`,
    });
  }

  // âœ… ADD URL CONTENT FIRST (for product comparisons)
  if (urlContent && urlContent.length > 0) {
    finalMessages.push({
      role: "system",
      content: `WEBSITE CONTENT FOR ANALYSIS:\n${urlContent}`,
    });
    console.log(
      `ðŸ”— Added URL content: ${urlContent.length.toLocaleString()} characters`
    );
  }

  // âœ… ADD COMPLETE FILE CONTEXT - NO LIMITS
  if (fileContext && fileContext.length > 0) {
    finalMessages.push({
      role: "system",
      content: `COMPLETE FILE CONTENT:\n${fileContext}`,
    });
    console.log(
      `ðŸ“„ Added COMPLETE file context: ${fileContext.length.toLocaleString()} characters`
    );
    // console.log(`ðŸ“„ First 300 chars of context: ${fileContext.substring(0, 300)}`);
  }
  // Add this debug line in buildAIMessagesWithSmartContext
  console.log(
    "ðŸ” DEBUG - fileContext parameter:",
    fileContext?.substring(0, 200)
  );
  console.log("ðŸ” DEBUG - fileContext length:", fileContext?.length);

  // Add current document context if available (new upload)
  // if (extracted_summary && extracted_summary !== "Success" && extracted_summary !== "No readable content") {
  //   finalMessages.push({
  //     role: "system",
  //     content: `ADDITIONAL NEW DOCUMENT:\n${extracted_summary}`,
  //   });
  // }


  // If semantic chunks are available, add them as a system prompt for the AI
// If semantic chunks are available, add them as a system prompt for the AI
if (fileContextResult?.semanticResults?.hasResults && fileContextResult?.semanticResults?.chunksFound > 0) {
  const chunkDetails = (fileContextResult.semanticResults.chunks || []).map((chunk, idx) =>
    `CHUNK ${idx + 1}:
File: ${chunk.fileName}
Page: ${chunk.pageNumber}
Relevance Score: ${(chunk.score || 0).toFixed(2)}
Keywords Matched: ${chunk.keywordHits || 0}
Content: ${chunk.text || "No content available"}`
  ).join('\n\n' + '='.repeat(50) + '\n\n');
  
  finalMessages.push({
    role: "system",
    content: `DOCUMENT ANALYSIS CONTEXT:

You have access to ${fileContextResult.semanticResults.chunksFound} document chunks that were retrieved based on semantic similarity and keyword matching to the user's query.

INSTRUCTIONS:
1. Analyze ALL provided chunks carefully
2. Look for information that directly answers the user's question
3. Consider partial matches and related information
4. If you find relevant information, provide a comprehensive answer
5. If no direct answer exists, mention what related information you found
6. Always cite the specific page numbers when referencing information

RETRIEVED CHUNKS:
${chunkDetails}

Use your judgment to determine which chunks contain the most relevant information for answering the user's question. Don't be overly restrictive - if information is related or could be helpful, include it in your response.`,
  });
}




  // Add user message
  finalMessages.push({ role: "user", content: userMessage || "" });

  // âœ… LOG TOTAL CONTEXT SIZE
  const totalContextLength = finalMessages.reduce(
    (total, msg) => total + msg.content.length,
    0
  );
  const estimatedTokens = Math.ceil(totalContextLength / 4);

   console.log(`ðŸ§  AI Context Summary:`);
  console.log(`   - Total Messages: ${finalMessages.length}`);
  console.log(`   - Total Characters: ${totalContextLength.toLocaleString()}`);
  console.log(`   - Estimated Tokens: ${estimatedTokens.toLocaleString()}`);
  console.log(`   - URL Content: ${urlContent ? "INCLUDED" : "None"}`);
  console.log(`   - File Context: ${fileContext ? "ENHANCED WITH SEMANTIC SEARCH" : "None"}`);
  if (fileContextResult?.semanticResults?.hasResults) {
    console.log(`   - Semantic Chunks: ${fileContextResult.semanticResults.chunksFound}`);
    console.log(`   - Semantic Files: ${fileContextResult.semanticResults.filesInvolved.join(', ')}`);
    console.log(`   - Context Preview: "${fileContext.substring(0, 200)}..."`);
  }


  return finalMessages;
}
const fileAnalysisCache = new Map();
const CACHE_TTL = 300000; // 5 minutes

function getCachedFileAnalysis(userMessage) {
  const key = userMessage.toLowerCase().trim();
  const cached = fileAnalysisCache.get(key);

  if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
    return cached.analysis;
  }

  const analysis = intelligentFileDetectionAnalysis(userMessage);
  fileAnalysisCache.set(key, {
    analysis,
    timestamp: Date.now(),
  });

  // Clean cache periodically
  if (fileAnalysisCache.size > 100) {
    const oldEntries = Array.from(fileAnalysisCache.entries()).filter(
      ([_, value]) => Date.now() - value.timestamp > CACHE_TTL
    );
    oldEntries.forEach(([key]) => fileAnalysisCache.delete(key));
  }

  return analysis;
}

function logAIPerformance(startTime, operation, details = {}) {
  const duration = Date.now() - startTime;
  const emoji = duration < 1000 ? "âš¡" : duration < 3000 ? "ðŸš€" : "â±ï¸";

  console.log(`${emoji} ${operation}: ${duration}ms`, details);

  // Log slow operations for optimization
  if (duration > 5000) {
    console.warn(`ðŸŒ SLOW OPERATION: ${operation} took ${duration}ms`, details);
  }
}

// âœ… SIMPLE: AI File Generation Handler
const handleAIFileGeneration = async (
  aiResponse,
  conversation_id,
  user_id,
  res
) => {
  console.log(`ðŸ” Smart file generation check...`);

  const generatedFiles = [];
  let cleanedResponse = aiResponse;
  const FileGenerator = require("../utils/fileGenerator");

  console.log(`ðŸ” Searching for CREATE_FILE in ${aiResponse.length} chars`);
  console.log(
    `ðŸ” Raw response contains CREATE_FILE: ${aiResponse.includes(
      "[CREATE_FILE:"
    )}`
  );

  // âœ… FIXED: Manual parsing to handle content with brackets properly
  const createFileMatches = [];
  let searchText = aiResponse;

  while (searchText.includes("[CREATE_FILE:")) {
    const startIndex = searchText.indexOf("[CREATE_FILE:");
    if (startIndex === -1) break;

    // Find the matching closing bracket by counting brackets
    let endIndex = -1;
    let bracketCount = 0;
    let inContent = false;
    let colonCount = 0;

    for (let i = startIndex; i < searchText.length; i++) {
      const char = searchText[i];

      if (char === "[") {
        bracketCount++;
      } else if (char === "]") {
        bracketCount--;
        // Only close if we're at bracket count 0 and we've seen at least 2 colons (type:filename:content)
        if (bracketCount === 0 && colonCount >= 2) {
          endIndex = i;
          break;
        }
      } else if (char === ":" && bracketCount === 1 && !inContent) {
        colonCount++;
        if (colonCount === 2) {
          inContent = true; // Now we're in the content section
        }
      }
    }

    if (endIndex === -1) {
      // If no proper closing bracket found, take everything till the end
      endIndex = searchText.length - 1;
    }

    const fullTag = searchText.substring(startIndex, endIndex + 1);
    createFileMatches.push(fullTag);

    console.log(
      `ðŸ” Extracted full tag (${fullTag.length} chars): ${fullTag.substring(
        0,
        200
      )}...`
    );

    // Remove this match and continue searching
    searchText = searchText.substring(endIndex + 1);

    if (createFileMatches.length >= 5) break; // Safety limit
  }

  console.log(`ðŸ” Found ${createFileMatches.length} CREATE_FILE tags`);

  let fileCount = 0;
  for (const fullTag of createFileMatches) {
    if (fileCount >= 5) break;
    fileCount++;

    console.log(`ðŸ“ Processing file ${fileCount}:`);
    console.log(`   - Full tag length: ${fullTag.length} chars`);
    console.log(`   - Tag preview: ${fullTag.substring(0, 100)}...`);

    let fileType = "";
    let filename = "";
    let content = "";

    try {
      // âœ… FIXED: Proper parsing - remove only the brackets, not the CREATE_FILE: part
      const tagContent = fullTag.slice(1, -1); // Remove [ and ]
      console.log(
        `   - Tag content after bracket removal: ${tagContent.substring(
          0,
          100
        )}...`
      );

      // Now remove CREATE_FILE: prefix
      if (!tagContent.startsWith("CREATE_FILE:")) {
        throw new Error(
          "Invalid CREATE_FILE format: missing CREATE_FILE prefix"
        );
      }

      const contentAfterPrefix = tagContent.substring(12); // Remove 'CREATE_FILE:'
      console.log(
        `   - Content after prefix removal: ${contentAfterPrefix.substring(
          0,
          100
        )}...`
      );

      // Find first colon for file type
      const firstColonIndex = contentAfterPrefix.indexOf(":");
      if (firstColonIndex === -1) {
        throw new Error("Invalid CREATE_FILE format: missing type separator");
      }

      fileType = contentAfterPrefix.substring(0, firstColonIndex).trim();

      // Find second colon for filename
      const remainingAfterType = contentAfterPrefix.substring(
        firstColonIndex + 1
      );
      const secondColonIndex = remainingAfterType.indexOf(":");
      if (secondColonIndex === -1) {
        throw new Error(
          "Invalid CREATE_FILE format: missing filename separator"
        );
      }

      filename = remainingAfterType.substring(0, secondColonIndex).trim();
      content = remainingAfterType.substring(secondColonIndex + 1); // Don't trim here to preserve formatting

      console.log(`   - Type: "${fileType}"`);
      console.log(`   - Filename: "${filename}"`);
      console.log(`   - Raw content length: ${content.length} chars`);
      console.log(
        `   - Raw content preview: "${content.substring(0, 150)}..."`
      );

      // âœ… FAST VALIDATION
      if (!fileType || !filename || content.length < 20) {
        throw new Error(
          `Invalid file data: type=${fileType}, name=${filename}, content=${content.length}chars`
        );
      }

      // âœ… OPTIMIZED CONTENT PROCESSING
      const cleanFilename = filename
        .replace(/\.(pdf|docx|xlsx|txt)$/i, "")
        .replace(/[^a-zA-Z0-9_\-\s]/g, "");

      // âœ… FIXED: Proper content decoding with better newline handling
      const decodedContent = content
        .replace(/\\n\\n/g, "\n\n") // Double newlines first
        .replace(/\\n/g, "\n") // Then single newlines
        .replace(/\\t/g, "\t")
        .replace(/\\\"/g, '"')
        .replace(/\\\'/g, "'")
        .replace(/\\r/g, "\r")
        .trim(); // Only trim at the end

      console.log(
        `   - Decoded content length: ${decodedContent.length} chars`
      );
      console.log(
        `   - Decoded preview: "${decodedContent.substring(0, 200)}..."`
      );

      if (decodedContent.length < 30) {
        throw new Error(
          `Content too short after decoding: ${decodedContent.length} characters`
        );
      }

      // âœ… IMMEDIATE FILE GENERATION (no delays)
      console.log(`âš¡ Generating ${fileType} file: ${cleanFilename}`);

      const fileResult = await FileGenerator.generateFromAI(
        fileType,
        decodedContent,
        cleanFilename,
        conversation_id,
        user_id
      );

      if (fileResult.success) {
        generatedFiles.push(fileResult);

        // âœ… PARALLEL DATABASE SAVE (don't wait)
        saveGeneratedFileToDatabase(
          fileResult,
          conversation_id,
          user_id,
          decodedContent
        ).catch((err) => console.error("âŒ DB save failed:", err));

        // âœ… PROFESSIONAL REPLACEMENT
        const displayName = fileResult.originalFilename || cleanFilename;
        const downloadLink = `\n\nðŸ“„ **${displayName}.${fileType}** - Professional document created!\nðŸ”— [**Download ${displayName}**](${fileResult.downloadUrl})\n`;
        cleanedResponse = cleanedResponse.replace(fullTag, downloadLink);

        console.log(`âœ… File created: ${fileResult.filename}`);

        // âœ… IMMEDIATE FRONTEND NOTIFICATION
        res.write(
          JSON.stringify({
            type: "file_ready",
            filename: displayName,
            download_url: fileResult.downloadUrl,
            file_type: fileType,
          }) + "\n"
        );
      } else {
        throw new Error(fileResult.error || "File generation failed");
      }
    } catch (error) {
      console.error(`âŒ File ${fileCount} creation failed:`, error.message);

      const cleanFilename =
        filename?.replace(/\.(pdf|docx|xlsx|txt)$/i, "") || `file_${fileCount}`;
      cleanedResponse = cleanedResponse.replace(
        fullTag,
        `\nâŒ **Could not create ${cleanFilename}.${
          fileType || "docx"
        }**\n*Error: ${error.message}*\n`
      );

      // âœ… IMMEDIATE ERROR NOTIFICATION
      res.write(
        JSON.stringify({
          type: "file_error",
          filename: cleanFilename,
          error: error.message,
          file_type: fileType || "docx",
        }) + "\n"
      );
    }
  }

  console.log(
    `ðŸŽ¯ File generation completed: ${generatedFiles.length}/${fileCount} successful`
  );

  return {
    hasGeneratedFiles: generatedFiles.length > 0,
    cleanedResponse,
    generatedFiles,
  };
};

// âœ… FIXED: Database save function
const saveGeneratedFileToDatabase = async (
  fileData,
  conversation_id,
  user_id,
  originalTextContent = null
) => {
  try {
    const metadata = {
      original_filename: fileData.originalFilename || fileData.filename,
      actual_filename: fileData.filename,
      file_size: fileData.size,
      mime_type: fileData.mimeType,
      ai_generated: true,
      created_at: new Date().toISOString(),
      ftp_path: fileData.ftpPath,
      download_url: fileData.downloadUrl,
    };

    await executeQuery(
      `INSERT INTO generated_files 
       (conversation_id, user_id, filename, file_data, file_metadata, mime_type, file_size, ftp_path, download_url) 
       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)`,
      [
        conversation_id,
        user_id,
        fileData.filename,
        originalTextContent || "", // âœ… Store original text with UTF-8 support
        JSON.stringify(metadata),
        fileData.mimeType,
        fileData.size,
        fileData.ftpPath,
        fileData.downloadUrl,
      ]
    );

    console.log(`âœ… File saved to database: ${fileData.filename}`);
  } catch (error) {
    console.error(`âŒ Database save failed:`, error);
    throw error;
  }
};

async function generateFastSuggestions(userMessage, aiResponse = null) {
  try {
    // Build context from both user message and AI response
    let context = userMessage || "Continue the conversation";

    if (aiResponse && aiResponse.trim().length > 20) {
      // Add AI response context (first 500 chars for efficiency)
      const responsePreview =
        aiResponse.length > 500
          ? aiResponse.substring(0, 500) + "..."
          : aiResponse;
      context = `User asked: "${userMessage}"\nAI responded: "${responsePreview}"`;
    }

    const suggestionResult = await deepseek.chat.completions.create({
      model: "deepseek-chat",
      messages: [
        {
          role: "system",
          content:
            "Based on the conversation, generate 5 short follow-up questions that the user would naturally ask next. Make them specific to the topics discussed. Reply only with numbered list.",
        },
        { role: "user", content: context },
      ],
      temperature: 0.8,
      max_tokens: 120, // Increased slightly for better quality
    });

    const rawSuggestion = suggestionResult.choices?.[0]?.message?.content || "";
    return rawSuggestion
      .split("\n")
      .map((s) =>
        s
          .replace(/^[\s\d\-â€¢.]+/, "")
          .replace(/[.?!]+$/, "")
          .trim()
      )
      .filter(Boolean)
      .slice(0, 5);
  } catch (error) {
    console.error("âŒ Fast suggestion failed:", error);
    return [
      "Can you explain this further?",
      "What are some examples?",
      "How can I apply this?",
    ];
  }
}

// âœ… ENHANCED BACKGROUND TASKS WITH FILE SAVING (Continued)
async function handleAllBackgroundTasksOptimizedWithFiles(
  conversation_id,
  userMessage,
  aiResponse,
  extracted_summary,
  suggestions,
  user_id,
  shouldRename,
  newConversationName,
  processedUrls = [],
  urlData = [],
  urlContent = "",
  fileContext = "",
  _file_upload_ids = [],
  generatedFiles = null // âœ… New parameter
) {
  try {
    console.log(
      "ðŸ”„ Starting enhanced background tasks with file generation support"
    );

    if (!user_id || isNaN(user_id)) {
      console.error("âŒ Invalid user_id in background tasks:", user_id);
      return;
    }

    // ðŸš€ STEP 1: Create conversation if needed
    if (!conversation_id || isNaN(conversation_id)) {
      try {
        const conversationResult = await executeQuery(
          "INSERT INTO conversations (user_id, name) VALUES (?, ?)",
          [
            user_id,
            newConversationName || userMessage?.substring(0, 20) || "New Chat",
          ]
        );

        conversation_id = conversationResult.insertId;
        console.log(
          "âœ… Created new conversation:",
          conversation_id,
          "for user:",
          user_id
        );
      } catch (convError) {
        console.error("âŒ Conversation creation failed:", convError);
        return;
      }
    }

    // âœ… GET ACTUAL FILE DATA FROM DATABASE
    let uploadedFiles = [];
    if (conversation_id) {
      try {
        const recentFiles = await executeQuery(
          `SELECT file_path, file_metadata, extracted_text, created_at 
           FROM uploaded_files 
           WHERE conversation_id = ? AND user_id = ? 
           AND created_at >= DATE_SUB(NOW(), INTERVAL 5 MINUTE)
           AND (status = 'confirmed' OR status = 'pending_response' OR status IS NULL)
           ORDER BY created_at DESC`,
          [conversation_id, user_id]
        );

        uploadedFiles = recentFiles || [];
        console.log(
          `ðŸ“ Found ${uploadedFiles.length} recent files for chat history`
        );
      } catch (fileError) {
        console.error("âŒ Error fetching recent files:", fileError);
      }
    }

    // ðŸš€ STEP 2: Parallel background operations with timeout
    const backgroundTasks = [
      // Save to database with generated file info
      Promise.race([
        saveToDatabase(
          conversation_id,
          userMessage,
          aiResponse,
          uploadedFiles,
          extracted_summary,
          suggestions,
          processedUrls,
          urlData,
          fileContext,
          _file_upload_ids,
          generatedFiles,
          user_id // âœ… Pass generated file data
        ),
        new Promise((resolve) =>
          setTimeout(() => resolve({ timeout: true }), 5000)
        ),
      ]),

      // Rename conversation ONLY if needed
      shouldRename
        ? Promise.race([
            executeRename(conversation_id, userMessage, user_id),
            new Promise((resolve) =>
              setTimeout(() => resolve({ timeout: true }), 3000)
            ),
          ])
        : Promise.resolve(false),

      // Generate comprehensive summary with file context
      Promise.race([
        generateAndSaveComprehensiveSummary(
          conversation_id,
          userMessage,
          aiResponse,
          urlContent,
          fileContext
        ),
        new Promise((resolve) =>
          setTimeout(() => resolve({ timeout: true }), 8000)
        ),
      ]),
    ];

    const [dbResult, renameResult, summaryResult, fileResult] =
      await Promise.allSettled(backgroundTasks);

    console.log("âœ… Enhanced background tasks completed:", {
      database:
        dbResult.status === "fulfilled" && !dbResult.value?.timeout
          ? "âœ… Saved"
          : "âŒ Failed/Timeout",
      rename: shouldRename
        ? renameResult.status === "fulfilled" && !renameResult.value?.timeout
          ? "âœ… Done"
          : "âŒ Failed/Timeout"
        : "â­ï¸ Skipped",
      summary:
        summaryResult.status === "fulfilled" && !summaryResult.value?.timeout
          ? "âœ… Generated"
          : "âŒ Failed/Timeout",
      generated_files: generatedFiles // âœ… FIXED variable name
        ? generatedFiles.length > 0
          ? "âœ… Saved"
          : "â­ï¸ No files generated"
        : "â­ï¸ No files generated",
      conversation_id: conversation_id,
      user_id: user_id,
      urls_processed: Array.isArray(urlData) ? urlData.length : 0,
    });
  } catch (error) {
    console.error("âŒ Enhanced background tasks failed:", error);
  }
}

// âœ… NEW: Save all generated files to database
const saveAllGeneratedFilesToDatabase = async (
  conversation_id,
  generatedFiles,
  user_id
) => {
  if (!generatedFiles || generatedFiles.length === 0) return null;

  try {
    const savedFiles = [];

    for (const fileData of generatedFiles) {
      const fileMetadata = {
        original_filename: fileData.filename,
        display_filename: fileData.filename,
        unique_filename: fileData.filename,
        file_size: fileData.size,
        mime_type: fileData.mimeType,
        file_type: "ai_generated",
        generated_at: new Date().toISOString(),
        is_ai_generated: true,
        ftp_path: fileData.ftpPath,
        download_url: fileData.downloadUrl,
      };

      const result = await executeQuery(
        `INSERT INTO generated_files 
         (conversation_id, user_id, filename, file_data, file_metadata, mime_type, file_size, ftp_path, download_url, created_at) 
         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, NOW())`,
        [
          conversation_id,
          user_id,
          fileData.filename,
          fileData.buffer ? fileData.buffer.toString("base64") : null, // Optional: store buffer
          JSON.stringify(fileMetadata),
          fileData.mimeType,
          fileData.size,
          fileData.ftpPath,
          fileData.downloadUrl,
        ]
      );

      savedFiles.push({
        id: result.insertId,
        filename: fileData.filename,
        download_url: fileData.downloadUrl,
      });

      console.log(
        `âœ… AI-generated file saved to database: ${fileData.filename}`
      );
    }

    return savedFiles;
  } catch (error) {
    console.error("âŒ Failed to save generated files to database:", error);
    return null;
  }
};
// âœ… ENHANCED SAVE TO DATABASE WITH GENERATED FILE INFO
async function saveToDatabase(
  conversation_id,
  userMessage,
  aiResponse,
  uploadedFiles,
  extracted_summary,
  suggestions,
  processedUrls = [],
  urlData = [],
  fileContext = "",
  _file_upload_ids = [],
  generatedFiles = null,
  user_id = null // âœ… New parameter
) {
  try {
    // âœ… Handle uploaded files (existing logic)
    let filePaths = [];
    let fileNames = [];
    let fileMetadataArray = [];

    const hasNewFiles =
      _file_upload_ids &&
      Array.isArray(_file_upload_ids) &&
      _file_upload_ids.length > 0;

    if (hasNewFiles) {
      console.log(
        `ðŸ“ New files detected - Processing ${_file_upload_ids.length} file IDs`
      );

      const placeholders = _file_upload_ids.map(() => "?").join(",");
      const newFiles = await executeQuery(
        `SELECT file_path, file_metadata, extracted_text, created_at 
         FROM uploaded_files 
         WHERE id IN (${placeholders})
         AND conversation_id = ?`,
        [..._file_upload_ids, conversation_id]
      );

      console.log(
        `ðŸ“ Found ${newFiles.length} files for IDs: ${_file_upload_ids.join(
          ", "
        )}`
      );

      if (newFiles && newFiles.length > 0) {
        newFiles.forEach((file) => {
          if (file.file_path) {
            filePaths.push(file.file_path);
          }

          if (file.file_metadata) {
            try {
              const metadata = JSON.parse(file.file_metadata);
              fileNames.push(
                metadata.original_filename ||
                  metadata.display_filename ||
                  "Unknown"
              );
              fileMetadataArray.push(file.file_metadata);
            } catch (parseError) {
              console.error("âŒ Error parsing file metadata:", parseError);
              fileNames.push("Unknown");
            }
          } else {
            fileNames.push("Unknown");
          }
        });
      }
    } else {
      console.log("ðŸ“ No new files - Skipping file data save");
    }

    // âœ… Handle generated files info
    // âœ… Handle generated files info
    let generatedFilesInfo = null;
    if (generatedFiles && generatedFiles.length > 0) {
      generatedFilesInfo = generatedFiles.map((file) => ({
        filename: file.filename,
        file_type: file.fileType,
        download_url: file.downloadUrl,
        size: file.size,
        ai_generated: true,
      }));
    }

    // Prepare data for database
    const filePathsString = filePaths.length > 0 ? filePaths.join(",") : null;
    const fileNamesString = fileNames.length > 0 ? fileNames.join(",") : null;
    const fileMetadataString =
      fileMetadataArray.length > 0 ? JSON.stringify(fileMetadataArray) : null;

    // âœ… URL processing (existing logic)
    const urlsString =
      processedUrls.length > 0 ? processedUrls.join(",") : null;
    const urlContentString =
      urlData.length > 0
        ? urlData
            .map((data, index) => {
              const status = data.error ? "FAILED" : "SUCCESS";
              const siteType = data.metadata?.siteType || "unknown";
              const contentLength = data.content?.length || 0;
              const content =
                data.content && !data.error
                  ? data.content
                  : `[ERROR: ${data.error}]`;

              return `[URL ${index + 1} - ${status} - ${siteType.toUpperCase()}]
URL: ${data.url}
Title: ${data.title || "No title"}
Description: ${data.description || "No description"}
Content Length: ${contentLength} characters
Site Type: ${siteType}

Content:
${content}

${"=".repeat(100)}`;
            })
            .join("\n\n")
        : null;

    const urlMetadata =
      urlData.length > 0
        ? JSON.stringify(
            urlData.map((data) => ({
              url: data.url,
              title: data.title,
              success: !data.error,
              error: data.error || null,
              site_type: data.metadata?.siteType,
              content_length: data.content?.length || 0,
              extraction_method: data.metadata?.extractionMethod,
              hostname: data.metadata?.hostname,
              processed_at: new Date().toISOString(),
            }))
          )
        : null;

    // âœ… COMBINE EXTRACTED TEXT WITH URL CONTENT
    let allExtractedText = "";
    if (extracted_summary) {
      allExtractedText += `CURRENT UPLOAD:\n${extracted_summary}\n\n`;
    }
    if (fileContext) {
      allExtractedText += `PREVIOUS FILES:\n${fileContext}\n\n`;
    }
    if (urlContentString) {
      allExtractedText += `URL CONTENT (${urlData.length} URLs):\n${urlContentString}`;
    }

    // âœ… INSERT QUERY WITH GENERATED FILE INFO
    await executeQuery(
      `INSERT INTO chat_history 
       (conversation_id, user_message, response, created_at, file_path, extracted_text, file_names, file_metadata, suggestions, urls, url_content, url_metadata, generated_file_info) 
       VALUES (?, ?, ?, NOW(), ?, ?, ?, ?, ?, ?, ?, ?, ?)`,
      [
        conversation_id,
        userMessage,
        aiResponse,
        filePathsString,
        allExtractedText || null,
        fileNamesString,
        fileMetadataString,
        suggestions && suggestions.length > 0
          ? JSON.stringify(suggestions)
          : null,
        urlsString,
        urlContentString,
        urlMetadata,
        generatedFilesInfo ? JSON.stringify(generatedFilesInfo) : null, // âœ… New field
      ]
    );

    console.log("âœ… Enhanced database save successful:", {
      has_new_files: hasNewFiles,
      file_upload_ids: _file_upload_ids,
      new_files_saved: filePaths.length,
      has_generated_files: !!(generatedFiles && generatedFiles.length > 0), // âœ… FIXED
      generated_files_count: generatedFiles ? generatedFiles.length : 0, // âœ… FIXED
      total_urls: processedUrls.length,
      successful_urls: urlData.filter((d) => !d.error).length,
    });

    return true;
  } catch (error) {
    console.error("âŒ Enhanced database save error:", error);
    throw error;
  }
}

// ðŸ·ï¸ EXECUTE RENAME WITH USER VALIDATION AND AI TITLE GENERATION - Async function
async function executeRename(conversation_id, userMessage, user_id) {
  try {
    // Generate AI title based on user message
    const aiGeneratedTitle = await generateConversationTitle(userMessage);

    await executeQuery(
      "UPDATE conversations SET name = ? WHERE id = ? AND user_id = ?",
      [aiGeneratedTitle, conversation_id, user_id]
    );

    console.log(
      `ðŸ·ï¸ Conversation renamed to: "${aiGeneratedTitle}" for user:`,
      user_id
    );
    return { success: true, title: aiGeneratedTitle };
  } catch (error) {
    console.error("âŒ Rename execution error:", error);
    throw error;
  }
}

// ðŸ¤– GENERATE AI TITLE BASED ON USER MESSAGE - Async function
async function generateConversationTitle(userMessage) {
  try {
    if (!userMessage || userMessage.length < 5) {
      return "New Conversation";
    }

    const titleResult = await deepseek.chat.completions.create({
      model: "deepseek-chat",
      messages: [
        {
          role: "system",
          content:
            "Generate a short, descriptive title (3-6 words) for a conversation based on the user's first message. Reply with only the title, no quotes or extra text.",
        },
        {
          role: "user",
          content: userMessage.substring(0, 200), // Limit input for efficiency
        },
      ],
      temperature: 0.3,
      max_tokens: 20,
    });

    const aiTitle = titleResult.choices?.[0]?.message?.content?.trim();

    if (aiTitle && aiTitle.length > 0 && aiTitle.length <= 50) {
      console.log(`ðŸ¤– AI generated title: "${aiTitle}"`);
      return aiTitle;
    }

    // Fallback to truncated user message
    return userMessage.length > 20
      ? userMessage.substring(0, 17) + "..."
      : userMessage;
  } catch (error) {
    console.error("âŒ AI title generation failed:", error);
    // Fallback to truncated user message
    return userMessage.length > 20
      ? userMessage.substring(0, 17) + "..."
      : userMessage;
  }
}

// ðŸ¤– GENERATE COMPREHENSIVE SUMMARY OF CONVERSATION - Async function
async function generateAndSaveComprehensiveSummary(
  conversation_id,
  currentUserMessage,
  currentAiResponse,
  urlContent = "",
  fileContext = ""
) {
  try {
    console.log("ðŸ§  Generating lightweight summary with Llama...");

    // âœ… ONLY get chat history (no file content)
    const fullHistory = await executeQuery(
      "SELECT user_message, response FROM chat_history WHERE conversation_id = ? ORDER BY created_at ASC",
      [conversation_id]
    );

    // âœ… ONLY get file NAMES (not content)
    const allConversationFiles = await executeQuery(
      `SELECT file_metadata FROM uploaded_files 
       WHERE conversation_id = ? 
       AND (status = 'confirmed' OR status = 'pending_response' OR status IS NULL)
       ORDER BY created_at ASC`,
      [conversation_id]
    );
    // âœ… GET ALL URLS FROM THIS CONVERSATION
    const allConversationUrls = await executeQuery(
      `SELECT urls, url_metadata FROM chat_history 
   WHERE conversation_id = ? AND urls IS NOT NULL
   ORDER BY created_at ASC`,
      [conversation_id]
    );

    // âœ… Create URL summary for the comprehensive summary
    let urlSummary = "";
    const importantUrls = new Set();

    if (allConversationUrls && allConversationUrls.length > 0) {
      allConversationUrls.forEach((chat) => {
        if (chat.urls) {
          const urls = chat.urls.split(",");
          urls.forEach((url) => importantUrls.add(url.trim()));
        }

        // Extract successful URLs from metadata
        if (chat.url_metadata) {
          try {
            const metadata = JSON.parse(chat.url_metadata);
            metadata.forEach((urlMeta) => {
              if (urlMeta.success && urlMeta.site_type) {
                importantUrls.add(`${urlMeta.url} [${urlMeta.site_type}]`);
              }
            });
          } catch (e) {
            // Ignore parsing errors
          }
        }
      });

      if (importantUrls.size > 0) {
        urlSummary = `\n\nIMPORTANT URLs REFERENCED:\n${Array.from(
          importantUrls
        )
          .slice(0, 10)
          .join("\n")}`;
      }
    }

    // âœ… Build conversation WITHOUT file content
    const completeConversation = [];

    fullHistory.forEach((chat) => {
      if (chat.user_message) {
        // âœ… LIMIT user message length for summary
        const limitedUserMessage =
          chat.user_message.length > 300
            ? chat.user_message.substring(0, 300) + "..."
            : chat.user_message;

        completeConversation.push({
          role: "user",
          content: limitedUserMessage,
        });
      }

      if (chat.response) {
        // âœ… LIMIT AI response length for summary
        const limitedResponse =
          chat.response.length > 400
            ? chat.response.substring(0, 400) + "..."
            : chat.response;

        completeConversation.push({
          role: "assistant",
          content: limitedResponse,
        });
      }
    });

    // Add current exchange (also limited)
    const currentUserLimited =
      currentUserMessage.length > 300
        ? currentUserMessage.substring(0, 300) + "..."
        : currentUserMessage;

    const currentAiLimited =
      currentAiResponse.length > 400
        ? currentAiResponse.substring(0, 400) + "..."
        : currentAiResponse;

    completeConversation.push({ role: "user", content: currentUserLimited });
    completeConversation.push({ role: "assistant", content: currentAiLimited });

    // âœ… NEW: Extract last 4 messages for better accuracy
    const recentMessages = completeConversation.slice(-4);
    const recentMessagesText = recentMessages
      .map((msg) => `${msg.role}: ${msg.content}`)
      .join("\n");

    // âœ… Create file names summary (NOT content)
    let filesSummary = "";
    if (allConversationFiles && allConversationFiles.length > 0) {
      const fileNames = [];
      allConversationFiles.forEach((file) => {
        if (file.file_metadata) {
          try {
            const metadata = JSON.parse(file.file_metadata);
            fileNames.push(
              metadata.original_filename || metadata.display_filename
            );
          } catch (e) {}
        }
      });

      if (fileNames.length > 0) {
        filesSummary = `\n\nFiles mentioned in conversation: ${fileNames.join(
          ", "
        )}`;
      }
    }

    // âœ… Build conversation text (limited length)
    const conversationText = completeConversation
      .map((msg) => `${msg.role}: ${msg.content}`)
      .join("\n");

    // âœ… SAFE: Limit total conversation text to prevent token overflow
    const maxConversationLength = 8000; // Safe limit
    const finalConversationText =
      conversationText.length > maxConversationLength
        ? conversationText.substring(0, maxConversationLength) +
          "\n...[Earlier messages truncated for summary]"
        : conversationText;

    console.log(
      `ðŸ“Š Creating summary: ${completeConversation.length} messages, ${finalConversationText.length} chars, last 4 messages: ${recentMessages.length}`
    );

    // âœ… ENHANCED summary prompt with recent messages for better accuracy
    const summaryPrompt = [
      {
        role: "system",
        content: `Create a concise conversation summary focusing on:

1. Main topics and questions discussed
2. User's key needs and preferences  
3. Important decisions or recommendations made
4. Technical details or specific requests mentioned
5. Files mentioned by name (not content)

Keep it under 400 words for efficient context loading. Focus on conversation flow, not file content.

Also include any important URLs or websites that were referenced and discussed in the conversation.

Pay special attention to the recent messages for the most current context and user intent.`,
      },
      {
        role: "user",
        content: `Full conversation to summarize:\n${finalConversationText}${filesSummary}${urlSummary}

RECENT MESSAGES (for better accuracy):
${recentMessagesText}`,
      },
    ];

    // âœ… USE LLAMA for summary generation
    const summaryResult = await llama.chat.completions.create({
      messages: summaryPrompt,
      temperature: 0.2,
      max_tokens: 600, // Reduced for efficiency
    });

    const summary = summaryResult.choices?.[0]?.message?.content || "";

    if (summary && summary.length > 10) {
      await executeQuery(
        "UPDATE chat_history SET summarized_chat = ? WHERE conversation_id = ? ORDER BY created_at DESC LIMIT 1",
        [summary, conversation_id]
      );

      console.log("âœ… Lightweight summary generated with Llama:", {
        length: summary.length,
        message_count: completeConversation.length,
        recent_messages_count: recentMessages.length,
        files_mentioned: allConversationFiles.length,
        urls_mentioned: importantUrls.size,
        conversation_id: conversation_id,
        model: "Llama",
        summary_preview: summary.substring(0, 100) + "...",
      });

      return true;
    }

    console.log("âš ï¸ Summary generation failed - empty or too short");
    return false;
  } catch (error) {
    console.error("âŒ Summary generation failed:", error.message);

    // âœ… SIMPLE fallback summary
    try {
      let basicSummary = `User discussed: ${currentUserMessage.substring(
        0,
        150
      )}${
        currentUserMessage.length > 150 ? "..." : ""
      }. AI provided assistance with this topic.`;

      if (urlContent) {
        basicSummary += " URLs were referenced.";
      }

      // âœ… Only mention file count, not content
      const fileCount = allConversationFiles?.length || 0;
      if (fileCount > 0) {
        basicSummary += ` ${fileCount} files were discussed.`;
      }
      // âœ… Mention URL count
      const urlCount = importantUrls?.size || 0;
      if (urlCount > 0) {
        basicSummary += ` ${urlCount} URLs were referenced.`;
      }

      await executeQuery(
        "UPDATE chat_history SET summarized_chat = ? WHERE conversation_id = ? ORDER BY created_at DESC LIMIT 1",
        [basicSummary, conversation_id]
      );

      console.log("âœ… Fallback summary saved with Llama");
      return true;
    } catch (fallbackError) {
      console.error("âŒ Even fallback summary failed:", fallbackError);
      return false;
    }
  }
}

exports.guestChat = async (req, res) => {
  const { userMessage } = req.body;
  if (!userMessage || typeof userMessage !== "string") {
    return res.status(400).json({ error: "Message is required." });
  }

  try {
    // Set headers for streaming
    res.writeHead(200, {
      "Content-Type": "text/plain; charset=utf-8",
      "Transfer-Encoding": "chunked",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Headers": "Cache-Control",
    });

    // ðŸš€ IMMEDIATE PARALLEL PROCESSING - Start all tasks simultaneously
    const startTime = Date.now();

    // Task 1: URL Processing (Non-blocking)
    const urlProcessingPromise = processUrlsOptimizedGuest(userMessage, res);

    // ðŸ“… Get current date
    const currentDate = new Date().toLocaleDateString("en-US", {
      year: "numeric",
      month: "long",
      day: "numeric",
    });

    // ðŸ§  Enhanced system prompt with URL capabilities for guest mode
    const systemPrompt = {
      role: "system",
      content: `You are QhashAI, an AI assistant by QuantumHash team (2024). Current date: ${currentDate}.

You can analyze and understand content from URLs that users share. When referencing URL content, be specific about which website or source you're citing.

Be helpful, accurate, and concise. This is guest mode, so provide complete responses without requiring conversation history.`,
    };

    const messages = [systemPrompt];

    // We'll add URL content after processing
    let aiResponse = "";

    try {
      // Send initial metadata immediately
      res.write(
        JSON.stringify({
          type: "start",
          guest_mode: true,
          context: {
            url_processing_started: true,
          },
          processing_time: Date.now() - startTime,
        }) + "\n"
      );

      // ðŸš€ START AI RESPONSE STREAM IMMEDIATELY (Don't wait for URLs)
      let finalMessages = [...messages];
      finalMessages.push({ role: "user", content: userMessage });

      const stream = await deepseek.chat.completions.create({
        model: "deepseek-chat",
        messages: finalMessages,
        temperature: 0.7,
        max_tokens: 1200,
        stream: true,
      });

      console.log(`ðŸš€ Guest AI stream started in ${Date.now() - startTime}ms`);

      // Stream the response chunks
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || "";
        if (content) {
          aiResponse += content;
          res.write(
            JSON.stringify({
              type: "content",
              content: content,
            }) + "\n"
          );
        }
      }

      // Wait for URL processing to complete
      const urlResult = await urlProcessingPromise;
      const { urlData, urlContent, processedUrls } = urlResult;

      // ðŸš€ GENERATE SIMPLE CONTEXTUAL SUGGESTIONS AFTER AI RESPONSE
      console.log("ðŸŽ¯ Generating guest suggestions based on conversation...");
      const suggestions = await generateFastGuestSuggestions(
        userMessage,
        aiResponse
      );

      // Send final data
      res.write(
        JSON.stringify({
          type: "end",
          suggestions: suggestions,
          full_response: aiResponse,
          guest_mode: true,
          processed_urls: urlData.map((data) => ({
            url: data.url,
            title: data.title,
            success: !data.error,
            error: data.error,
            site_type: data.metadata?.siteType, // Optional enhancement
            content_length: data.content?.length || 0, // Optional enhancement
          })),
          context: {
            url_content_available: !!urlContent,
            urls_processed: urlData.length,
          },
          total_processing_time: Date.now() - startTime,
        }) + "\n"
      );

      res.end();

      // ðŸ“Š Optional: Log guest interactions with URLs for analytics (without storing personal data)
      if (urlData.length > 0) {
        console.log(
          `ðŸ“Š Guest interaction: ${urlData.length} URLs processed, ${
            urlData.filter((d) => !d.error).length
          } successful`
        );
      }
    } catch (aiError) {
      console.error("AI API error in guest mode:", aiError);
      res.write(
        JSON.stringify({
          type: "error",
          error:
            "I'm having trouble processing your request. Please try again.",
          guest_mode: true,
        }) + "\n"
      );
      res.end();
    }
  } catch (error) {
    console.error("âŒ Guest chat error:", error.stack || error.message);
    if (!res.headersSent) {
      res.status(500).json({ error: "Internal server error." });
    }
  }
};

// ðŸš€ OPTIMIZED URL PROCESSING FOR GUEST - Non-blocking with immediate feedback
async function processUrlsOptimizedGuest(userMessage, res) {
  let urlData = [];
  let urlContent = "";
  let processedUrls = [];

  if (!userMessage) {
    return { urlData, urlContent, processedUrls };
  }

  const extractedUrls = extractUrls(userMessage);

  if (extractedUrls.length === 0) {
    return { urlData, urlContent, processedUrls };
  }

  console.log(
    `ðŸ”— Guest mode: Found ${extractedUrls.length} URLs - processing optimized`
  );

  // Send URL processing status immediately
  res.write(
    JSON.stringify({
      type: "url_processing",
      status: "started",
      urls: extractedUrls,
      count: extractedUrls.length,
      guest_mode: true,
    }) + "\n"
  );

  try {
    // âš¡ Process URLs with timeout and parallel processing
    const urlPromises = extractedUrls.map(async (url) => {
      try {
        // Set a 3-second timeout for each URL
        const timeoutPromise = new Promise((_, reject) =>
          setTimeout(() => reject(new Error("URL processing timeout")), 3000)
        );

        const urlProcessPromise = processUrls([url]);

        const result = await Promise.race([urlProcessPromise, timeoutPromise]);
        return result[0]; // processUrls returns array
      } catch (error) {
        console.error(`âŒ URL processing failed for ${url}:`, error.message);
        return {
          url: url,
          title: "Failed to load",
          content: "",
          error: error.message,
        };
      }
    });

    // Wait for all URLs with a maximum 4-second total timeout
    const allUrlsPromise = Promise.all(urlPromises);
    const totalTimeoutPromise = new Promise((resolve) =>
      setTimeout(() => {
        console.log(
          "âš ï¸ Guest URL processing timeout - proceeding with partial results"
        );
        resolve([]);
      }, 4000)
    );

    urlData = await Promise.race([allUrlsPromise, totalTimeoutPromise]);

    if (urlData && urlData.length > 0) {
      processedUrls = extractedUrls;

      // Create URL content summary
      urlContent = urlData
        .filter((data) => data && data.content && !data.error)
        .map(
          (data) =>
            `URL: ${data.url}\nTitle: ${
              data.title
            }\nContent: ${data.content.substring(0, 1500)}\n---`
        )
        .join("\n");

      // Send completion status
      res.write(
        JSON.stringify({
          type: "url_processing",
          status: "completed",
          processed: urlData.length,
          successful: urlData.filter((d) => d && !d.error).length,
          guest_mode: true,
        }) + "\n"
      );
    }
  } catch (error) {
    console.error("âŒ Guest URL processing error:", error);
    res.write(
      JSON.stringify({
        type: "url_processing",
        status: "error",
        error: "Failed to process URLs",
        guest_mode: true,
      }) + "\n"
    );
  }

  return { urlData, urlContent, processedUrls };
}

// ðŸš€ SIMPLE FAST SUGGESTIONS FOR GUEST CHAT
async function generateFastGuestSuggestions(userMessage, aiResponse = null) {
  try {
    // Build context from both user message and AI response
    let context = userMessage || "Continue the conversation";

    if (aiResponse && aiResponse.trim().length > 20) {
      // Add AI response context (first 500 chars for efficiency)
      const responsePreview =
        aiResponse.length > 500
          ? aiResponse.substring(0, 500) + "..."
          : aiResponse;
      context = `User asked: "${userMessage}"\nAI responded: "${responsePreview}"`;
    }

    const suggestionResult = await deepseek.chat.completions.create({
      model: "deepseek-chat",
      messages: [
        {
          role: "system",
          content:
            "Based on the conversation, generate 3 short follow-up questions that the user would naturally ask next. Make them specific to the topics discussed. Reply only with numbered list.",
        },
        { role: "user", content: context },
      ],
      temperature: 0.8,
      max_tokens: 100, // Reduced for guest mode speed
    });

    const rawSuggestion = suggestionResult.choices?.[0]?.message?.content || "";
    const suggestions = rawSuggestion
      .split("\n")
      .map((s) =>
        s
          .replace(/^[\s\d\-â€¢.]+/, "")
          .replace(/[.?!]+$/, "")
          .trim()
      )
      .filter(Boolean)
      .slice(0, 3); // Only 3 suggestions for guest mode

    return suggestions.length > 0 ? suggestions : [];
  } catch (error) {
    console.error("âŒ Guest suggestion failed:", error);
    return [];
  }
}

//  delete function
exports.softDeleteConversation = async (req, res) => {
  const { id } = req.params;
  const userId = req.user?.user_id;

  // âœ… USER VALIDATION
  if (!userId || isNaN(userId)) {
    console.error("âŒ Invalid user_id in softDeleteConversation:", userId);
    return res.status(401).json({ error: "Unauthorized: Invalid user ID" });
  }

  console.log("ðŸ” Soft deleting conversation:", id, "for user:", userId);

  try {
    // Step 1: Check if the conversation exists and belongs to the user
    const conversationCheck = await executeQuery(
      "SELECT id FROM conversations WHERE id = ? AND user_id = ? AND is_deleted = FALSE",
      [id, userId]
    );

    if (!conversationCheck || conversationCheck.length === 0) {
      console.error(
        "âŒ Unauthorized delete attempt - conversation:",
        id,
        "user:",
        userId
      );
      return res
        .status(404)
        .json({ error: "Conversation not found or unauthorized" });
    }

    // Step 2: Count remaining conversations after potential deletion
    const remainingConversationsResult = await executeQuery(
      "SELECT COUNT(*) as count FROM conversations WHERE user_id = ? AND is_deleted = FALSE AND id != ?",
      [userId, id]
    );

    const remainingConversations = remainingConversationsResult[0]?.count || 0;

    // Step 3: Check if there's chat history in the conversation being deleted
    const chatHistoryResult = await executeQuery(
      "SELECT COUNT(*) as count FROM chat_history WHERE conversation_id = ?",
      [id]
    );

    const hasChatHistory = (chatHistoryResult[0]?.count || 0) > 0;

    // Step 4: Apply the logic based on your requirements
    if (remainingConversations > 0) {
      // There are other conversations left, safe to delete this one
      await executeQuery(
        "UPDATE conversations SET is_deleted = TRUE WHERE id = ? AND user_id = ?",
        [id, userId]
      );

      console.log(
        `âœ… Conversation ${id} soft deleted. ${remainingConversations} conversations remaining for user ${userId}.`
      );

      return res.json({
        success: true,
        message: "Conversation deleted successfully",
        action: "deleted",
      });
    } else {
      // This is the last conversation
      if (hasChatHistory) {
        // Has chat history: delete it and create/select a new conversation using createConversation logic

        // First, delete the current conversation
        await executeQuery(
          "UPDATE conversations SET is_deleted = TRUE WHERE id = ? AND user_id = ?",
          [id, userId]
        );

        console.log(
          `ðŸ—‘ï¸ Deleted last conversation ${id} with chat history for user ${userId}`
        );

        // Now use the same logic as createConversation to find/create and select a conversation
        const defaultName =
          (await generateConversationTitle("New Conversation")) ||
          "New Conversation";

        // Step 1: Find the most recent conversation for this user (excluding the deleted one)
        const recentConversations = await executeQuery(
          `SELECT id, name FROM conversations 
   WHERE user_id = ? AND is_deleted = FALSE
   ORDER BY created_at DESC 
   LIMIT 1`,
          [userId]
        );

        if (recentConversations && recentConversations.length > 0) {
          const recentConversation = recentConversations[0];

          // Step 2: Check if this conversation has any messages
          const messageCountResult = await executeQuery(
            `SELECT COUNT(*) as count FROM chat_history WHERE conversation_id = ?`,
            [recentConversation.id]
          );

          const messageCount = messageCountResult[0]?.count || 0;

          // If no messages, reuse this conversation
          if (messageCount === 0) {
            console.log(
              "ðŸ”„ Reused empty conversation:",
              recentConversation.id,
              "for user:",
              userId
            );
            return res.status(200).json({
              success: true,
              conversation_id: recentConversation.id,
              name: recentConversation.name,
              action: "deleted_and_selected_existing",
              message:
                "Conversation deleted and existing empty conversation selected",
              selected: true,
            });
          }
        }

        // Step 3: Create new conversation if none exists or recent one has messages
        const newConversationResult = await executeQuery(
          "INSERT INTO conversations (user_id, name) VALUES (?, ?)",
          [userId, defaultName]
        );

        const conversation_id = newConversationResult.insertId;

        if (!conversation_id) {
          throw new Error("Failed to get insert ID");
        }

        console.log(
          "âœ… Created and selected new conversation:",
          conversation_id,
          "for user:",
          userId
        );

        return res.status(201).json({
          success: true,
          conversation_id,
          name: defaultName,
          action: "deleted_and_created_new",
          message:
            "Conversation deleted and new conversation created and selected",
          selected: true,
        });
      } else {
        // No chat history: keep the conversation (it's a feature!)
        console.log(
          `ðŸ’¡ Keeping conversation ${id} - it's your workspace and ready for new chats for user ${userId}!`
        );

        return res.status(200).json({
          success: true,
          message:
            "This is your active workspace! Start a new conversation here.",
          action: "kept_as_workspace",
          conversation_id: parseInt(id),
          workspace: true,
        });
      }
    }
  } catch (error) {
    console.error(
      "âŒ Error in soft delete conversation for user",
      userId,
      ":",
      error
    );
    res.status(500).json({ error: "Internal server error" });
  }
};

// âœ… SMART CONTENT VALIDATOR
function validateFileContent(content, fileType) {
  if (!content || content.length < 50) {
    return { valid: false, reason: "Content too short" };
  }

  // Type-specific validation
  switch (fileType.toLowerCase()) {
    case "docx":
      if (!content.includes("\n") && content.length < 100) {
        return { valid: false, reason: "Document content seems incomplete" };
      }
      break;
    case "xlsx":
      if (
        !content.includes("|") &&
        !content.includes("\t") &&
        !content.includes(",")
      ) {
        return {
          valid: false,
          reason: "Spreadsheet should contain tabular data",
        };
      }
      break;
    case "pdf":
      if (content.length < 200) {
        return { valid: false, reason: "PDF content too minimal" };
      }
      break;
  }

  return { valid: true };
}

// âœ… PROFESSIONAL FILENAME GENERATOR
function generateProfessionalFilename(originalName, fileType, userInfo = null) {
  let cleanName = originalName
    .replace(/[^a-zA-Z0-9_\-\s]/g, "")
    .replace(/\s+/g, "_")
    .substring(0, 50);

  // Add user context if available
  if (userInfo && userInfo.username) {
    const userName = userInfo.username.replace(/[^a-zA-Z0-9]/g, "");
    if (!cleanName.toLowerCase().includes(userName.toLowerCase())) {
      cleanName = `${cleanName}_${userName}`;
    }
  }

  // Add timestamp for uniqueness
  const timestamp = new Date().toISOString().slice(0, 10).replace(/-/g, "");

  return `${cleanName}_${timestamp}`;
}

// âœ… RESPONSE QUALITY ANALYZER
function analyzeResponseQuality(userMessage, aiResponse, fileAnalysis) {
  const analysis = {
    score: 0,
    issues: [],
    suggestions: [],
  };

  // Check if file creation was requested but not delivered
  if (fileAnalysis.shouldCreateFile && !aiResponse.includes("[CREATE_FILE:")) {
    analysis.issues.push("File creation requested but not provided");
    analysis.score -= 30;
  }

  // Check response length appropriateness
  if (userMessage.length > 100 && aiResponse.length < 200) {
    analysis.issues.push("Response may be too brief for detailed request");
    analysis.score -= 10;
  }

  // Check for professional formatting
  if (fileAnalysis.shouldCreateFile && aiResponse.includes("[CREATE_FILE:")) {
    if (!aiResponse.includes("**") && !aiResponse.includes("*")) {
      analysis.suggestions.push(
        "Consider adding more formatting to file content"
      );
      analysis.score -= 5;
    }
  }

  // Base score
  analysis.score += 70;

  return analysis;
}

// âœ… PERFORMANCE MONITOR
class PerformanceMonitor {
  constructor() {
    this.metrics = new Map();
  }

  start(operation) {
    this.metrics.set(operation, {
      startTime: Date.now(),
      endTime: null,
      duration: null,
    });
  }

  end(operation) {
    const metric = this.metrics.get(operation);
    if (metric) {
      metric.endTime = Date.now();
      metric.duration = metric.endTime - metric.startTime;

      // Log slow operations
      if (metric.duration > 3000) {
        console.warn(`ðŸŒ SLOW: ${operation} took ${metric.duration}ms`);
      } else if (metric.duration < 500) {
        console.log(`âš¡ FAST: ${operation} took ${metric.duration}ms`);
      }
    }
  }

  getMetrics() {
    const results = {};
    for (const [operation, metric] of this.metrics.entries()) {
      results[operation] = metric.duration;
    }
    return results;
  }

  reset() {
    this.metrics.clear();
  }
}

// âœ… GLOBAL PERFORMANCE MONITOR INSTANCE
const performanceMonitor = new PerformanceMonitor();

// âœ… ENHANCED ERROR RECOVERY
async function handleCriticalError(error, context, res) {
  console.error(`ðŸš¨ CRITICAL ERROR in ${context}:`, error);

  // Try to provide helpful error message based on error type
  let userMessage =
    "I'm experiencing technical difficulties. Please try again.";

  if (error.message.includes("timeout")) {
    userMessage =
      "The request is taking longer than expected. Please try again with a shorter message.";
  } else if (error.message.includes("token")) {
    userMessage =
      "Your request is quite complex. Please try breaking it into smaller parts.";
  } else if (error.message.includes("file")) {
    userMessage =
      "There was an issue with file processing. Please try uploading your files again.";
  }

  if (!res.headersSent) {
    res.write(
      JSON.stringify({
        type: "error",
        error: userMessage,
        context: context,
        timestamp: new Date().toISOString(),
        recoverable: true,
      }) + "\n"
    );
  }
}

// âœ… EXPORT PERFORMANCE MONITOR FOR TESTING
module.exports.performanceMonitor = performanceMonitor;
